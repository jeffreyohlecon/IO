{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please comment your code clearly, as the clarity of your code will also\n",
    "# be evaluated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1\n",
    "\n",
    "\n",
    " # unlike in YG's example, no $\\Pi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Reading CSV and ensuring each market has an outside good row...\n",
      ">>> Building first-stage weighting matrix W1 = (Z'Z)^-1 ...\n",
      ">>> Starting FIRST pass GMM optimization...\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 310 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 310 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 310 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 310 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 310 iterations.\n",
      "beta\n",
      "[-0.40535423 -2.41233908]\n",
      "obj\n",
      "881.4338015082142\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 352 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 352 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 352 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 352 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 352 iterations.\n",
      "beta\n",
      "[-0.46070226 -1.92049398]\n",
      "obj\n",
      "743.6311534822323\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 542 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 542 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 542 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 542 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 542 iterations.\n",
      "beta\n",
      "[-0.90853044 -1.99113082]\n",
      "obj\n",
      "1056.4370230405752\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 401 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 401 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 401 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 401 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 401 iterations.\n",
      "beta\n",
      "[-0.57225067 -1.74336419]\n",
      "obj\n",
      "705.7339992603268\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1088 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1088 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1088 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1088 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1088 iterations.\n",
      "beta\n",
      "[-1.56688876 -0.85391697]\n",
      "obj\n",
      "677.1614242293695\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1393 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1393 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1393 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1393 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1393 iterations.\n",
      "beta\n",
      "[-1.76369169 -0.55328462]\n",
      "obj\n",
      "668.0851286570573\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1238 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1238 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1238 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1238 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1238 iterations.\n",
      "beta\n",
      "[-1.72981163 -0.61195825]\n",
      "obj\n",
      "663.7373219672891\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1234 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1234 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1234 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1234 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1234 iterations.\n",
      "beta\n",
      "[-1.73012469 -0.61212061]\n",
      "obj\n",
      "663.7065432933794\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1233 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1233 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1233 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1233 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1233 iterations.\n",
      "beta\n",
      "[-1.7281587  -0.61340665]\n",
      "obj\n",
      "663.7059074128417\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      "beta\n",
      "[-1.72667915 -0.61455306]\n",
      "obj\n",
      "663.705835204726\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.sandbox.regression.gmm as gmm\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS\n",
    "\n",
    "##############################################################################\n",
    "# 1. Read Data & Construct Outside Good\n",
    "##############################################################################\n",
    "def read_data_with_outside_good(csv_path):\n",
    "    \"\"\"\n",
    "    Reads a dataset that has columns:\n",
    "        market, choice, shares, p, x, z1, z2, ...\n",
    "    If the outside good (choice=0) is *not* in the CSV, this function\n",
    "    creates a synthetic row for each market with p0=x0=0, share=1-sum(shares_in_market),\n",
    "    and zeros for instruments if needed.\n",
    "    \"\"\"\n",
    "    print(\">>> Reading CSV and ensuring each market has an outside good row...\")\n",
    "    df = pd.read_csv(csv_path).copy()\n",
    "    df.sort_values(by=[\"market\", \"choice\"], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    frames = []\n",
    "    for m in df[\"market\"].unique():\n",
    "        this_mkt = df.loc[df[\"market\"] == m].copy()\n",
    "        outside_row = this_mkt.loc[this_mkt[\"choice\"] == 0]\n",
    "\n",
    "        if outside_row.empty:\n",
    "            sum_inside = this_mkt[\"shares\"].sum()\n",
    "            outside_share = max(0.0, 1.0 - sum_inside)\n",
    "            row_outside = {\n",
    "                \"market\": m,\n",
    "                \"choice\": 0,\n",
    "                \"shares\": outside_share,\n",
    "                \"p\": 0.0,\n",
    "                \"x\": 0.0,\n",
    "            }\n",
    "            # For z1,z2,... set to 0\n",
    "            for c in this_mkt.columns:\n",
    "                if c.startswith(\"z\"):\n",
    "                    row_outside[c] = 0.0\n",
    "            this_mkt = pd.concat([this_mkt, pd.DataFrame([row_outside])],\n",
    "                                 ignore_index=True)\n",
    "\n",
    "        this_mkt.sort_values(\"choice\", inplace=True)\n",
    "        frames.append(this_mkt)\n",
    "\n",
    "    df_out = pd.concat(frames, ignore_index=True)\n",
    "    df_out.sort_values(by=[\"market\", \"choice\"], inplace=True)\n",
    "    df_out.reset_index(drop=True, inplace=True)\n",
    "    return df_out\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 2. Draw (vi) ~ N(0, I)\n",
    "##############################################################################\n",
    "def draw_taste_shocks(n_draws=50, seed=0):\n",
    "    \"\"\"\n",
    "    Return an array of shape (n_draws, 2) of normal(0,1) draws\n",
    "    for random coefficients dimension=2 (e.g., for price & x).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    v = rng.normal(0.0, 1.0, size=(n_draws, 2))\n",
    "    return v\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 3. Predict Shares (Vectorized)\n",
    "##############################################################################\n",
    "def predict_shares(delta, X, Gamma, v_draws, by_market):\n",
    "    \"\"\"\n",
    "    Vectorized share prediction:\n",
    "      s_j = (1/n_draws) sum_{i=1..n_draws} \n",
    "             exp( delta_j + X_j @ (Gamma v_i) )\n",
    "           / sum_{k} exp( delta_k + X_k @ (Gamma v_i) ),\n",
    "    by market.\n",
    "    \"\"\"\n",
    "    n_draws = v_draws.shape[0]\n",
    "    s_pred = np.zeros_like(delta)\n",
    "\n",
    "    # Precompute random coefficients for all draws => shape (n_draws, 2)\n",
    "    rc = (Gamma @ v_draws.T).T  # shape (n_draws, 2)\n",
    "\n",
    "    unique_mkts = np.unique(by_market)\n",
    "    for m_id in unique_mkts:\n",
    "        idx = (by_market == m_id)\n",
    "\n",
    "        delta_m = delta[idx]          # (#products_in_market,)\n",
    "        X_m     = X[idx,:]            # (#products_in_market, 2)\n",
    "\n",
    "        mu = X_m @ rc.T                             # (#products_in_market, n_draws)\n",
    "        util = delta_m[:, None] + mu                # (#products_in_market, n_draws)\n",
    "        exp_util = np.exp(util)\n",
    "\n",
    "        denom = exp_util.sum(axis=0)                # shape (n_draws,)\n",
    "        s_pred[idx] = (exp_util / denom).mean(axis=1)\n",
    "\n",
    "    return s_pred\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 4. Contraction Mapping\n",
    "##############################################################################\n",
    "def contraction_mapping(s_obs, X, Gamma, v_draws, by_market,\n",
    "                       tol=1e-6, max_iter=100000, print_every=500):\n",
    "    \"\"\"\n",
    "    Solves for delta_j subject to s_pred(delta) = s_obs.\n",
    "    Outside good => delta_0=0. We only update inside goods in the iteration.\n",
    "    \"\"\"\n",
    "    print(\">>> Starting contraction mapping to solve for delta_j...\")\n",
    "    outside_idx = np.all(np.isclose(X, 0.0), axis=1)  # index of outside good\n",
    "    inside_idx  = ~outside_idx\n",
    "\n",
    "    s_obs_safe = s_obs.clip(1e-16)\n",
    "    # Initialize delta via log(s_j)\n",
    "    delta = np.log(s_obs_safe)\n",
    "    delta[outside_idx] = 0.0  # delta for outside good set to 0\n",
    "\n",
    "    for iteration in range(max_iter):\n",
    "        if (iteration % print_every == 0) and (iteration > 0):\n",
    "            pct = 100.0 * iteration / max_iter\n",
    "            print(f\"    Contraction iteration: {iteration}/{max_iter} ({pct:.1f}% done)\")\n",
    "\n",
    "        s_pred = predict_shares(delta, X, Gamma, v_draws, by_market)\n",
    "        s_pred_safe = s_pred.clip(1e-16)\n",
    "\n",
    "        delta_new = delta.copy()\n",
    "        delta_new[inside_idx] = (\n",
    "            delta[inside_idx]\n",
    "            + np.log(s_obs_safe[inside_idx])\n",
    "            - np.log(s_pred_safe[inside_idx])\n",
    "        )\n",
    "        delta_new[outside_idx] = 0.0\n",
    "\n",
    "        sup_norm = np.max(np.abs(delta_new - delta))\n",
    "        delta = delta_new\n",
    "        if sup_norm < tol:\n",
    "            print(f\">>> Contraction mapping converged after {iteration+1} iterations.\")\n",
    "            break\n",
    "\n",
    "    return delta\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 5a. GMM Objective\n",
    "##############################################################################\n",
    "def gmm_objective(params, s_obs, X, Z, v_draws, by_market, W):\n",
    "    \"\"\"\n",
    "    Objective = (Z' xi)' W (Z' xi),\n",
    "    where xi = delta - X beta and delta solves the contraction mapping.\n",
    "    \"\"\"\n",
    "    gamma11, gamma21, gamma22 = params\n",
    "    Gamma = np.array([\n",
    "        [gamma11, 0.0],\n",
    "        [gamma21, gamma22]\n",
    "    ])\n",
    "\n",
    "    # Solve for delta\n",
    "    delta = contraction_mapping(s_obs, X, Gamma, v_draws, by_market,\n",
    "                                print_every=9999999)\n",
    "\n",
    "    # 2SLS to get beta\n",
    "    Z_with_const = sm.add_constant(Z, has_constant='add')\n",
    "    iv_model = IV2SLS(endog=delta, exog=X, instrument=Z_with_const)\n",
    "    iv_results = iv_model.fit()\n",
    "    beta = iv_results.params\n",
    "\n",
    "    xi = delta - X @ beta\n",
    "    m = Z.T @ xi\n",
    "    obj = m.T @ W @ m\n",
    "\n",
    "    return obj\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 5b. Helpers for gradient-based GMM\n",
    "##############################################################################\n",
    "def approximate_delta_grad(gamma, s_obs, X, v_draws, by_market,\n",
    "                           h=1e-5):\n",
    "    \"\"\"\n",
    "    Numerically approximate d(delta)/dGamma at the current Gamma.\n",
    "    gamma = [gamma11, gamma21, gamma22]\n",
    "    Returns: ddelta_dgamma, shape (N, 3)\n",
    "    \"\"\"\n",
    "    gamma11, gamma21, gamma22 = gamma\n",
    "    Gamma_base = np.array([[gamma11, 0.0],\n",
    "                           [gamma21, gamma22]])\n",
    "    delta_base = contraction_mapping(s_obs, X, Gamma_base, v_draws, by_market,\n",
    "                                     print_every=9999999)\n",
    "\n",
    "    n = len(delta_base)\n",
    "    ddelta_dgamma = np.zeros((n, 3))\n",
    "\n",
    "    for j in range(3):\n",
    "        step = np.zeros(3)\n",
    "        step[j] = h\n",
    "\n",
    "        Gamma_pert = np.array([\n",
    "            [gamma11 + step[0], 0.0],\n",
    "            [gamma21 + step[1], gamma22 + step[2]]\n",
    "        ])\n",
    "        delta_pert = contraction_mapping(s_obs, X, Gamma_pert, v_draws, by_market,\n",
    "                                         print_every=9999999)\n",
    "        ddelta_dgamma[:, j] = (delta_pert - delta_base) / (step[j])\n",
    "\n",
    "    return ddelta_dgamma\n",
    "\n",
    "def compute_2sls_beta(delta, X, Z):\n",
    "    \"\"\"\n",
    "    Compute 2SLS coefficient vector from model: delta = X beta + error\n",
    "    with instruments Z (including a constant).\n",
    "    \"\"\"\n",
    "    iv_model = gmm.IV2SLS(endog=delta, exog=X, instrument=Z)\n",
    "    results = iv_model.fit()\n",
    "    return results.params\n",
    "\n",
    "def gmm_objective_and_grad(gamma, s_obs, X, Z, v_draws, by_market, W):\n",
    "    \"\"\"\n",
    "    Returns: (objective, gradient wrt gamma),\n",
    "    where gamma = [gamma11, gamma21, gamma22].\n",
    "    \"\"\"\n",
    "    # 1) Build Gamma, solve for delta\n",
    "    gamma11, gamma21, gamma22 = gamma\n",
    "    Gamma = np.array([[gamma11, 0.0],\n",
    "                      [gamma21, gamma22]])\n",
    "    delta = contraction_mapping(s_obs, X, Gamma, v_draws, by_market,\n",
    "                                print_every=9999999)\n",
    "\n",
    "    # 2) Add constant in instruments\n",
    "    ones = np.ones((Z.shape[0], 1))\n",
    "    Z_with_const = np.hstack([ones, Z])\n",
    "\n",
    "    # 3) Compute 2SLS beta\n",
    "    beta_2sls = compute_2sls_beta(delta, X, Z_with_const)\n",
    "\n",
    "    # 4) xi = delta - X beta\n",
    "    xi = delta - X @ beta_2sls\n",
    "\n",
    "    # 5) Evaluate objective\n",
    "    m = Z.T @ xi\n",
    "    obj = m.T @ W @ m\n",
    "\n",
    "    # 6) We need d(delta)/d(gamma)\n",
    "    ddelta_dgamma = approximate_delta_grad(gamma, s_obs, X, v_draws, by_market)\n",
    "\n",
    "    # 7) Then d(beta)/d(gamma)\n",
    "    ZtZ_inv = np.linalg.inv(Z_with_const.T @ Z_with_const)\n",
    "    PZc = Z_with_const @ ZtZ_inv @ Z_with_const.T\n",
    "    XPZX = X.T @ PZc @ X\n",
    "    XPZX_inv = np.linalg.inv(XPZX)\n",
    "    B = XPZX_inv @ (X.T @ PZc)\n",
    "    n = len(delta)\n",
    "    M = np.eye(n) - X @ B  # shape (N, N)\n",
    "\n",
    "    # 8) derivative wrt xi of the objective: g_xi = 2 Z W (Z' xi)\n",
    "    g_xi = 2.0 * (Z @ (W @ (Z.T @ xi)))  # shape (N,)\n",
    "\n",
    "    # 9) gradient wrt gamma\n",
    "    ddelta = M @ ddelta_dgamma  # shape (N,3)\n",
    "    grad_gamma = ddelta.T @ g_xi  # shape (3,)\n",
    "    print(\"beta\")\n",
    "    print(beta_2sls)\n",
    "    print(\"obj\")\n",
    "    print(obj)\n",
    "    return obj, grad_gamma\n",
    "\n",
    "##############################################################################\n",
    "# 5c. Utility: get current xi for a given Gamma (for building W2)\n",
    "##############################################################################\n",
    "def get_xi_for_gamma(gamma, s_obs, X, Z, v_draws, by_market):\n",
    "    \"\"\"\n",
    "    Returns xi (N-vector), plus the final delta and the 2SLS beta,\n",
    "    all given the current gamma = [gamma11, gamma21, gamma22].\n",
    "    \"\"\"\n",
    "    gamma11, gamma21, gamma22 = gamma\n",
    "    Gamma = np.array([[gamma11, 0.0],\n",
    "                      [gamma21, gamma22]])\n",
    "    # Solve for delta\n",
    "    delta = contraction_mapping(s_obs, X, Gamma, v_draws, by_market,\n",
    "                                print_every=9999999)\n",
    "\n",
    "    # 2SLS\n",
    "    Z_with_const = sm.add_constant(Z, has_constant='add')\n",
    "    iv_model = IV2SLS(endog=delta, exog=X, instrument=Z_with_const)\n",
    "    iv_results = iv_model.fit()\n",
    "    beta = iv_results.params\n",
    "\n",
    "    xi = delta - X @ beta\n",
    "    return xi, delta, beta\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 6. Two-Step GMM with Progress Messages (NEW)\n",
    "##############################################################################\n",
    "def estimate_blp_iterative_gmm(df, n_draws=50, method=\"BFGS\", use_analytic_grad=True):\n",
    "    \"\"\"\n",
    "    1) Build Z, initial W1 = (Z'Z)^(-1)\n",
    "    2) Minimize GMM => res1\n",
    "    3) Recompute W => W2 from res1's estimates\n",
    "    4) Minimize => res2\n",
    "    Returns both passes.\n",
    "    \"\"\"\n",
    "    df.sort_values(by=[\"market\",\"choice\"], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    s_obs = df[\"shares\"].values\n",
    "    X = df[[\"p\",\"x\"]].values\n",
    "    z_cols = [c for c in df.columns if c.startswith(\"z\")]\n",
    "    if not z_cols:\n",
    "        raise ValueError(\"No instrument columns found!\")\n",
    "    Z = df[z_cols].values\n",
    "\n",
    "    by_market = df[\"market\"].values\n",
    "\n",
    "    print(\">>> Building first-stage weighting matrix W1 = (Z'Z)^-1 ...\")\n",
    "    ZZ = Z.T @ Z\n",
    "    eye_k = np.eye(ZZ.shape[0])\n",
    "    W1 = np.linalg.inv(ZZ + 1e-12 * eye_k)\n",
    "\n",
    "    # Draw taste shocks\n",
    "    v_draws = draw_taste_shocks(n_draws=n_draws, seed=0)\n",
    "\n",
    "    init_params = np.array([1,1,1])\n",
    "    print(\">>> Starting FIRST pass GMM optimization...\")\n",
    "\n",
    "    # Helper for first pass\n",
    "    if use_analytic_grad:\n",
    "        def obj_grad_fun_1(par):\n",
    "            return gmm_objective_and_grad(\n",
    "                par, s_obs, X, Z, v_draws, by_market, W1\n",
    "            )\n",
    "        res1 = minimize(\n",
    "            obj_grad_fun_1,\n",
    "            init_params,\n",
    "            method=method,\n",
    "            jac=True,\n",
    "            options={\"disp\": True, \"maxiter\": 10}\n",
    "        )\n",
    "    else:\n",
    "        def obj_fun_1(par):\n",
    "            return gmm_objective(\n",
    "                par, s_obs, X, Z, v_draws, by_market, W1\n",
    "            )\n",
    "        res1 = minimize(\n",
    "            obj_fun_1,\n",
    "            init_params,\n",
    "            method=method,\n",
    "            options={\"disp\": True, \"maxiter\": 10}\n",
    "        )\n",
    "\n",
    "    print(f\"    [FIRST PASS] success={res1.success}, \"\n",
    "          f\"params={res1.x}, obj={res1.fun:.6g}\")\n",
    "\n",
    "    # ------------------------\n",
    "    # 2nd Step: Build W2 using \\hat{x}\\hat{x}' from first pass\n",
    "    # ------------------------\n",
    "    print(\"\\n>>> Building second-stage weighting matrix W2 ...\")\n",
    "    gamma_hat_1 = res1.x\n",
    "    xi_1, _, _ = get_xi_for_gamma(gamma_hat_1, s_obs, X, Z, v_draws, by_market)\n",
    "    # moment = Z_i * xi_i.  We'll form S = sum_i (Z_i xi_i)(Z_i xi_i)' => (Z' * diag(xi) * Z),\n",
    "    # typically with a 1/N factor as well. We'll do the simplest approach:\n",
    "\n",
    "    # shape: (N, K)\n",
    "    ZX = Z * xi_1.reshape(-1,1)  # elementwise multiply each column of Z by xi\n",
    "    S_hat = ZX.T @ ZX  # shape (K,K), sum of outer products\n",
    "    # Optionally scale by 1/N or 1/(N-K).\n",
    "    N = Z.shape[0]\n",
    "    S_hat /= N\n",
    "\n",
    "    # W2 is inverse of S_hat\n",
    "    # (Add small ridge if needed for invertibility)\n",
    "    ridge = 1e-12 * np.eye(S_hat.shape[0])\n",
    "    W2 = np.linalg.inv(S_hat + ridge)\n",
    "\n",
    "    # 2nd pass optimization\n",
    "    print(\">>> Starting SECOND pass GMM optimization using W2...\")\n",
    "    if use_analytic_grad:\n",
    "        def obj_grad_fun_2(par):\n",
    "            return gmm_objective_and_grad(\n",
    "                par, s_obs, X, Z, v_draws, by_market, W2\n",
    "            )\n",
    "        res2 = minimize(\n",
    "            obj_grad_fun_2,\n",
    "            np.array([1,1,1]),   # do not use first pass estimate as initial\n",
    "            method=method,\n",
    "            jac=True,\n",
    "            options={\"disp\": True, \"maxiter\": 10}\n",
    "        )\n",
    "    else:\n",
    "        def obj_fun_2(par):\n",
    "            return gmm_objective(\n",
    "                par, s_obs, X, Z, v_draws, by_market, W2\n",
    "            )\n",
    "        res2 = minimize(\n",
    "            obj_fun_2,\n",
    "            np.array([1,1,1]),\n",
    "            method=method,\n",
    "            options={\"disp\": True, \"maxiter\": 50}\n",
    "        )\n",
    "\n",
    "    print(f\"    [SECOND PASS] success={res2.success}, \"\n",
    "          f\"params={res2.x}, obj={res2.fun:.6g}\")\n",
    "\n",
    "    return res1, res2\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 7. Main \n",
    "##############################################################################\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Read data, ensuring outside good rows\n",
    "    df_all = read_data_with_outside_good(\"ps1_ex4.csv\")\n",
    "\n",
    "    # 2)  Perform the two-step GMM estimation\n",
    "    first_pass, second_pass = estimate_blp_iterative_gmm(\n",
    "        df_all,\n",
    "        n_draws=50,\n",
    "        method=\"BFGS\",\n",
    "        use_analytic_grad=True\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== FINAL RESULTS ===\")\n",
    "    print(\"[FIRST PASS] success=\", first_pass.success)\n",
    "    print(\"  params=\", first_pass.x)\n",
    "    print(\"  objective=\", first_pass.fun)\n",
    "    print(\"[SECOND PASS] success=\", second_pass.success)\n",
    "    print(\"  params=\", second_pass.x)\n",
    "    print(\"  objective=\", second_pass.fun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gamma = np.array([[6.13440981 * 10**0, 0.00000000e+00],\n",
    "                  [-1.33296619 * 10**(-1), 2.85100016 * 10**(-3)]])\n",
    "\n",
    "# Multiply Gamma by its transpose\n",
    "Omega = np.dot(Gamma, Gamma.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.76309837e+01, -8.17696087e-01],\n",
       "       [-8.17696087e-01,  1.77761168e-02]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4.2    \n",
    " For each market, compute cross and own product elasticities. Average your results across\n",
    "markets and present them in a J ×J table whose (i, j) element contains the (average) elasticity\n",
    "of product i with respect to an increase in the price of product j. What’s the main difference\n",
    "when compared with the table of elasticities you found in 2.2?\n",
    "\n",
    "\n",
    "see slide 14 of Yonggeun's slides. we need to use the prices, shares, alpha_i (not clear how that maps to here) , and density of q_i (not sure how that maps to here), and density of v_i (assumed above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Average Price, x, and Share by Product}\n",
      "\\label{tab:avg_price_x_share}\n",
      "\\begin{tabular}{rrrr}\n",
      "\\toprule\n",
      "choice & avg_price & avg_x & avg_share \\\\\n",
      "\\midrule\n",
      "0 & 0.0000 & 0.0000 & 0.3848 \\\\\n",
      "1 & 0.0024 & -0.0193 & 0.0988 \\\\\n",
      "2 & 0.0023 & -0.0260 & 0.0891 \\\\\n",
      "3 & 2.0191 & -0.0813 & 0.0430 \\\\\n",
      "4 & 1.7516 & -0.1801 & 0.0393 \\\\\n",
      "5 & 3.5770 & 1.6926 & 0.1517 \\\\\n",
      "6 & 4.4429 & 2.0024 & 0.1932 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 look at average price and share for products, across market, using $\\Gamma$, what is driving differences in prices and market shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Group by product, compute mean for p, x, and shares\n",
    "table = (\n",
    "    df_all\n",
    "    .groupby('choice', as_index=False)\n",
    "    .agg(\n",
    "        avg_price=('p','mean'),\n",
    "        avg_x=('x','mean'),\n",
    "        avg_share=('shares','mean')\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2. Convert to LaTeX\n",
    "latex_table = table.to_latex(\n",
    "    index=False,\n",
    "    float_format=\"%.4f\",    # set decimal precision as needed\n",
    "    caption=\"Average Price, x, and Share by Product\",\n",
    "    label=\"tab:avg_price_x_share\"\n",
    ")\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 PyBLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyblp in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyblp) (2.1.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyblp) (0.5.6)\n",
      "Requirement already satisfied: pyhdfe>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyblp) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyblp) (1.14.1)\n",
      "Requirement already satisfied: sympy>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyblp) (1.13.3)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from patsy>=0.5.1->pyblp) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sympy>=1.1.0->pyblp) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyblp\n",
    "import pyblp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(prices + x, prices + x)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_blp = df_all.copy()\n",
    "df_blp = df_blp.rename(columns={'p': 'prices'})\n",
    "df_blp = df_blp.rename(columns={'choice': 'product_ids'})\n",
    "df_blp = df_blp.rename(columns={'market': 'market_ids'})\n",
    "\n",
    "\n",
    "\n",
    "df_blp = df_blp.rename(columns={'z1': 'demand_instruments0'})\n",
    "df_blp = df_blp.rename(columns={'z2': 'demand_instruments1'})\n",
    "df_blp = df_blp.rename(columns={'z3': 'demand_instruments2'})\n",
    "df_blp = df_blp.rename(columns={'z4': 'demand_instruments3'})\n",
    "df_blp = df_blp.rename(columns={'z5': 'demand_instruments4'})\n",
    "df_blp = df_blp.rename(columns={'z6': 'demand_instruments5'})\n",
    "\n",
    "\n",
    "df_blp = df_blp[df_blp['product_ids'] != 0]\n",
    "\n",
    "# X1 are things that have homog effects\n",
    "#X2 are (potentially same things) with heterog. effects\n",
    "X1_formulation = pyblp.Formulation('0+ prices + x') # no constant?\n",
    "X2_formulation = pyblp.Formulation('0 + prices + x') # random coefficient for outside good.? not in this model\n",
    "product_formulations = (X1_formulation,X2_formulation)\n",
    "product_formulations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_blp.product_ids.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_ids</th>\n",
       "      <th>product_ids</th>\n",
       "      <th>shares</th>\n",
       "      <th>prices</th>\n",
       "      <th>x</th>\n",
       "      <th>demand_instruments0</th>\n",
       "      <th>demand_instruments1</th>\n",
       "      <th>demand_instruments2</th>\n",
       "      <th>demand_instruments3</th>\n",
       "      <th>demand_instruments4</th>\n",
       "      <th>demand_instruments5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>-0.210973</td>\n",
       "      <td>-6.363361</td>\n",
       "      <td>-5.509449</td>\n",
       "      <td>-5.371022</td>\n",
       "      <td>-1.583637</td>\n",
       "      <td>-1.937069</td>\n",
       "      <td>-0.341810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2085</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>-1.557577</td>\n",
       "      <td>-5.198161</td>\n",
       "      <td>-4.396036</td>\n",
       "      <td>-4.265266</td>\n",
       "      <td>-2.862346</td>\n",
       "      <td>-3.498094</td>\n",
       "      <td>-2.330125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>1.016838</td>\n",
       "      <td>-0.799984</td>\n",
       "      <td>-0.040836</td>\n",
       "      <td>0.835758</td>\n",
       "      <td>-0.520122</td>\n",
       "      <td>-0.797271</td>\n",
       "      <td>0.768238</td>\n",
       "      <td>-0.973296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0348</td>\n",
       "      <td>0.109472</td>\n",
       "      <td>-1.338366</td>\n",
       "      <td>-1.538905</td>\n",
       "      <td>-1.172700</td>\n",
       "      <td>0.189448</td>\n",
       "      <td>-1.798173</td>\n",
       "      <td>1.519424</td>\n",
       "      <td>-0.264684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3661</td>\n",
       "      <td>5.387786</td>\n",
       "      <td>3.316330</td>\n",
       "      <td>0.758555</td>\n",
       "      <td>-0.700470</td>\n",
       "      <td>0.723864</td>\n",
       "      <td>-0.370940</td>\n",
       "      <td>-1.288456</td>\n",
       "      <td>0.080449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>4.188119</td>\n",
       "      <td>2.154527</td>\n",
       "      <td>1.044639</td>\n",
       "      <td>-0.724283</td>\n",
       "      <td>-1.325333</td>\n",
       "      <td>-1.520450</td>\n",
       "      <td>-0.922602</td>\n",
       "      <td>1.716677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   market_ids  product_ids  shares    prices         x  demand_instruments0  \\\n",
       "1           1            1  0.0099  0.000278 -0.210973            -6.363361   \n",
       "2           1            2  0.2085  0.000457 -1.557577            -5.198161   \n",
       "3           1            3  0.0090  1.016838 -0.799984            -0.040836   \n",
       "4           1            4  0.0348  0.109472 -1.338366            -1.538905   \n",
       "5           1            5  0.3661  5.387786  3.316330             0.758555   \n",
       "6           1            6  0.0231  4.188119  2.154527             1.044639   \n",
       "\n",
       "   demand_instruments1  demand_instruments2  demand_instruments3  \\\n",
       "1            -5.509449            -5.371022            -1.583637   \n",
       "2            -4.396036            -4.265266            -2.862346   \n",
       "3             0.835758            -0.520122            -0.797271   \n",
       "4            -1.172700             0.189448            -1.798173   \n",
       "5            -0.700470             0.723864            -0.370940   \n",
       "6            -0.724283            -1.325333            -1.520450   \n",
       "\n",
       "   demand_instruments4  demand_instruments5  \n",
       "1            -1.937069            -0.341810  \n",
       "2            -3.498094            -2.330125  \n",
       "3             0.768238            -0.973296  \n",
       "4             1.519424            -0.264684  \n",
       "5            -1.288456             0.080449  \n",
       "6            -0.922602             1.716677  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_blp[df_blp['market_ids'] ==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configured to construct nodes and weights with Monte Carlo simulation with options {seed: 0}."
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_integration = pyblp.Integration('monte_carlo', size=50, specification_options={'seed': 0})\n",
    "mc_integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the problem ...\n",
      "Initialized the problem after 00:00:00.\n",
      "\n",
      "Dimensions:\n",
      "================================\n",
      " T    N    I     K1    K2    MD \n",
      "---  ---  ----  ----  ----  ----\n",
      "100  600  5000   2     2     7  \n",
      "================================\n",
      "\n",
      "Formulations:\n",
      "==========================================\n",
      "       Column Indices:           0      1 \n",
      "-----------------------------  ------  ---\n",
      " X1: Linear Characteristics    prices   x \n",
      "X2: Nonlinear Characteristics  prices   x \n",
      "==========================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dimensions:\n",
       "================================\n",
       " T    N    I     K1    K2    MD \n",
       "---  ---  ----  ----  ----  ----\n",
       "100  600  5000   2     2     7  \n",
       "================================\n",
       "\n",
       "Formulations:\n",
       "==========================================\n",
       "       Column Indices:           0      1 \n",
       "-----------------------------  ------  ---\n",
       " X1: Linear Characteristics    prices   x \n",
       "X2: Nonlinear Characteristics  prices   x \n",
       "=========================================="
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_problem = pyblp.Problem(product_formulations, df_blp, integration=mc_integration)\n",
    "mc_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfgs = pyblp.Optimization('bfgs', {'gtol': 1e-4})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving the problem ...\n",
      "\n",
      "Nonlinear Coefficient Initial Values:\n",
      "=====================================================================================\n",
      "Sigma:     prices            x        |  Sigma Squared:     prices            x      \n",
      "------  -------------  -------------  |  --------------  -------------  -------------\n",
      "prices  +1.000000E+00                 |      prices      +1.000000E+00  +1.000000E+00\n",
      "  x     +1.000000E+00  +1.000000E+00  |        x         +1.000000E+00  +2.000000E+00\n",
      "=====================================================================================\n",
      "Starting optimization ...\n",
      "\n",
      "GMM   Computation  Optimization   Objective   Fixed Point  Contraction  Clipped    Objective      Objective      Gradient                                                \n",
      "Step     Time       Iterations   Evaluations  Iterations   Evaluations  Shares       Value       Improvement       Norm                          Theta                   \n",
      "----  -----------  ------------  -----------  -----------  -----------  -------  -------------  -------------  -------------  -------------------------------------------\n",
      " 1     00:00:00         0             1          1388         4254         0     +7.065720E+02                 +1.079111E+02  +1.000000E+00, +1.000000E+00, +1.000000E+00\n",
      " 1     00:00:00         0             2          1162         3586         0     +6.004930E+02  +1.060790E+02  +6.304642E+01  +1.042048E+00, +3.904101E-01, +1.958034E-01\n",
      " 1     00:00:00         1             3          1353         4155         0     +1.175646E+03                 +2.173146E+02  +8.667279E-01, -3.458975E+00, +1.082031E+00\n",
      " 1     00:00:00         1             4          1093         3361         0     +5.882695E+02  +1.222357E+01  +5.364650E+01  +1.026429E+00, +4.747493E-02, +2.747559E-01\n",
      " 1     00:00:00         2             5           942         2908         0     +6.006564E+02                 +4.109106E+01  -6.302781E-01, -2.062038E-01, -7.374380E-02\n",
      " 1     00:00:00         2             6           807         2489         0     +5.829037E+02  +5.365801E+00  +3.766030E+01  +4.506997E-01, -4.068207E-02, +1.536473E-01\n",
      " 1     00:00:00         3             7          1057         3257         0     +5.790095E+02  +3.894178E+00  +9.678597E+00  +1.073409E+00, -1.337940E-01, -1.807806E-02\n",
      " 1     00:00:00         4             8           971         2992         0     +5.785841E+02  +4.253729E-01  +7.587082E-01  +8.376065E-01, -1.124673E-01, +1.051049E-02\n",
      " 1     00:00:00         5             9           964         2981         0     +5.785696E+02  +1.449655E-02  +8.290528E-01  +8.922004E-01, -1.164217E-01, +1.793947E-02\n",
      " 1     00:00:00         6            10           970         2973         0     +5.785678E+02  +1.815969E-03  +5.718943E-02  +8.843425E-01, -1.164033E-01, +1.431905E-02\n",
      " 1     00:00:00         7            11           961         2951         0     +5.785678E+02  +9.100244E-06  +3.234854E-03  +8.837334E-01, -1.162670E-01, +1.453200E-02\n",
      " 1     00:00:00         8            12           964         2961         0     +5.785678E+02  +6.262553E-08  +7.229879E-04  +8.837962E-01, -1.162907E-01, +1.452724E-02\n",
      " 1     00:00:00         9            13           968         2970         0     +5.785678E+02  +1.440185E-09  +1.227298E-04  +8.838008E-01, -1.162865E-01, +1.452604E-02\n",
      " 1     00:00:00         10           14           967         2967         0     +5.785678E+02  +9.015366E-11  +1.679386E-06  +8.837985E-01, -1.162870E-01, +1.452635E-02\n",
      "\n",
      "Optimization completed after 00:00:01.\n",
      "Computing the Hessian and and updating the weighting matrix ...\n",
      "Computed results after 00:00:01.\n",
      "\n",
      "Problem Results Summary:\n",
      "=============================================================================================\n",
      "GMM     Objective      Gradient         Hessian         Hessian     Clipped  Weighting Matrix\n",
      "Step      Value          Norm       Min Eigenvalue  Max Eigenvalue  Shares   Condition Number\n",
      "----  -------------  -------------  --------------  --------------  -------  ----------------\n",
      " 1    +5.785678E+02  +1.679386E-06  +1.396032E+01   +2.600720E+02      0      +3.376106E+01  \n",
      "=============================================================================================\n",
      "\n",
      "Starting optimization ...\n",
      "\n",
      "GMM   Computation  Optimization   Objective   Fixed Point  Contraction  Clipped    Objective      Objective      Gradient                                                \n",
      "Step     Time       Iterations   Evaluations  Iterations   Evaluations  Shares       Value       Improvement       Norm                          Theta                   \n",
      "----  -----------  ------------  -----------  -----------  -----------  -------  -------------  -------------  -------------  -------------------------------------------\n",
      " 2     00:00:00         0             1            0           100         0     +1.625741E+02                 +1.571300E+00  +8.837985E-01, -1.162870E-01, +1.452635E-02\n",
      " 2     00:00:00         0             2           586         1841         0     +1.627749E+02                 +1.021095E+01  -9.348759E-02, +1.340024E-01, +6.317966E-02\n",
      " 2     00:00:00         0             3           745         2311         0     +1.623120E+02  +2.620247E-01  +5.608584E+00  +3.778272E-01, +1.329558E-02, +3.971567E-02\n",
      " 2     00:00:00         1             4           518         1648         0     +1.615517E+02  +7.603378E-01  +2.995124E+00  +3.891258E-02, -4.254746E-03, +9.719629E-03\n",
      " 2     00:00:00         1             5          1233         3797         0     +1.693650E+02                 +9.506341E+00  -1.316746E+00, -7.445607E-02, -1.102646E-01\n",
      " 2     00:00:00         1             6           587         1829         0     +1.619472E+02                 +6.268670E+00  -7.524953E-02, -1.016651E-02, -3.844272E-04\n",
      " 2     00:00:00         1             7           477         1513         0     +1.615231E+02  +2.858830E-02  +2.225150E+00  +2.240837E-02, -5.109399E-03, +8.258903E-03\n",
      " 2     00:00:00         2             8          1304         4004         0     +1.761703E+02                 +2.142444E+01  -1.320388E+00, -2.921484E-01, +5.030305E-01\n",
      " 2     00:00:00         2             9           487         1555         0     +1.616221E+02                 +5.001636E+00  -1.790718E-02, -1.372734E-02, +2.311372E-02\n",
      " 2     00:00:00         2            10           447         1425         0     +1.615187E+02  +4.434505E-03  +1.753214E+00  +1.611043E-02, -6.455660E-03, +1.057947E-02\n",
      " 2     00:00:00         3            11           486         1548         0     +1.615246E+02                 +1.962728E+00  +2.580459E-02, -1.669813E-02, +2.455832E-02\n",
      " 2     00:00:00         3            12           462         1477         0     +1.615174E+02  +1.326568E-03  +1.611225E+00  +1.899211E-02, -9.500328E-03, +1.473481E-02\n",
      " 2     00:00:00         4            13           460         1463         0     +1.615148E+02  +2.594038E-03  +1.506208E+00  +1.941915E-02, -1.080618E-02, +1.407247E-02\n",
      " 2     00:00:00         4            14           463         1471         0     +1.615061E+02  +8.665480E-03  +1.086369E+00  +2.112730E-02, -1.602957E-02, +1.142312E-02\n",
      " 2     00:00:00         5            15           474         1503         0     +1.614963E+02  +9.809219E-03  +1.032156E-02  +2.624718E-02, -2.992371E-02, +4.120471E-03\n",
      " 2     00:00:00         6            16           475         1502         0     +1.614963E+02  +1.080289E-06  +7.250599E-04  +2.638469E-02, -3.003756E-02, +4.069745E-03\n",
      " 2     00:00:00         7            17           475         1506         0     +1.614963E+02  +2.842057E-09  +1.340816E-05  +2.639259E-02, -3.004105E-02, +4.071025E-03\n",
      "\n",
      "Optimization completed after 00:00:01.\n",
      "Computing the Hessian and estimating standard errors ...\n",
      "Computed results after 00:00:00.\n",
      "\n",
      "Problem Results Summary:\n",
      "================================================================================================================\n",
      "GMM     Objective      Gradient         Hessian         Hessian     Clipped  Weighting Matrix  Covariance Matrix\n",
      "Step      Value          Norm       Min Eigenvalue  Max Eigenvalue  Shares   Condition Number  Condition Number \n",
      "----  -------------  -------------  --------------  --------------  -------  ----------------  -----------------\n",
      " 2    +1.614963E+02  +1.340816E-05  +5.220724E+01   +1.588827E+02      0      +1.724003E+01      +7.667105E+06  \n",
      "================================================================================================================\n",
      "\n",
      "Cumulative Statistics:\n",
      "===========================================================================\n",
      "Computation  Optimizer  Optimization   Objective   Fixed Point  Contraction\n",
      "   Time      Converged   Iterations   Evaluations  Iterations   Evaluations\n",
      "-----------  ---------  ------------  -----------  -----------  -----------\n",
      " 00:00:04       Yes          19           33          25688        79771   \n",
      "===========================================================================\n",
      "\n",
      "Nonlinear Coefficient Estimates (Robust SEs in Parentheses):\n",
      "=============================================================================================\n",
      "Sigma:      prices              x         |  Sigma Squared:      prices              x       \n",
      "------  ---------------  ---------------  |  --------------  ---------------  ---------------\n",
      "prices   +2.639259E-02                    |      prices       +6.965689E-04    -7.928612E-04 \n",
      "        (+5.355230E+00)                   |                  (+2.826768E-01)  (+4.562215E-01)\n",
      "                                          |                                                  \n",
      "  x      -3.004105E-02    +4.071025E-03   |        x          -7.928612E-04    +9.190380E-04 \n",
      "        (+1.254992E+01)  (+9.687154E+01)  |                  (+4.562215E-01)  (+1.451624E+00)\n",
      "=============================================================================================\n",
      "\n",
      "Beta Estimates (Robust SEs in Parentheses):\n",
      "================================\n",
      "    prices              x       \n",
      "---------------  ---------------\n",
      " +2.853686E-01    -6.960937E-01 \n",
      "(+6.477118E-01)  (+2.227513E+00)\n",
      "================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Problem Results Summary:\n",
       "================================================================================================================\n",
       "GMM     Objective      Gradient         Hessian         Hessian     Clipped  Weighting Matrix  Covariance Matrix\n",
       "Step      Value          Norm       Min Eigenvalue  Max Eigenvalue  Shares   Condition Number  Condition Number \n",
       "----  -------------  -------------  --------------  --------------  -------  ----------------  -----------------\n",
       " 2    +1.614963E+02  +1.340816E-05  +5.220724E+01   +1.588827E+02      0      +1.724003E+01      +7.667105E+06  \n",
       "================================================================================================================\n",
       "\n",
       "Cumulative Statistics:\n",
       "===========================================================================\n",
       "Computation  Optimizer  Optimization   Objective   Fixed Point  Contraction\n",
       "   Time      Converged   Iterations   Evaluations  Iterations   Evaluations\n",
       "-----------  ---------  ------------  -----------  -----------  -----------\n",
       " 00:00:04       Yes          19           33          25688        79771   \n",
       "===========================================================================\n",
       "\n",
       "Nonlinear Coefficient Estimates (Robust SEs in Parentheses):\n",
       "=============================================================================================\n",
       "Sigma:      prices              x         |  Sigma Squared:      prices              x       \n",
       "------  ---------------  ---------------  |  --------------  ---------------  ---------------\n",
       "prices   +2.639259E-02                    |      prices       +6.965689E-04    -7.928612E-04 \n",
       "        (+5.355230E+00)                   |                  (+2.826768E-01)  (+4.562215E-01)\n",
       "                                          |                                                  \n",
       "  x      -3.004105E-02    +4.071025E-03   |        x          -7.928612E-04    +9.190380E-04 \n",
       "        (+1.254992E+01)  (+9.687154E+01)  |                  (+4.562215E-01)  (+1.451624E+00)\n",
       "=============================================================================================\n",
       "\n",
       "Beta Estimates (Robust SEs in Parentheses):\n",
       "================================\n",
       "    prices              x       \n",
       "---------------  ---------------\n",
       " +2.853686E-01    -6.960937E-01 \n",
       "(+6.477118E-01)  (+2.227513E+00)\n",
       "================================"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to restrict parameters to be lower triangular. I think. Unclear. There's some documentation here talking about Cholesky decompositions.\n",
    "# Does seem like they ahve the taste shocks baked in here to some degree 'It is common to assume that 𝑓(𝛽𝑖∣𝜃) follows a multivariate normal distribution, and to break it up into three parts: \n",
    "\n",
    "# Might need to do something for beta too. \n",
    "results = mc_problem.solve(sigma= np.ones((2,2)), optimization=bfgs)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function numpy.ones(shape, dtype=None, order='C', *, device=None, like=None)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
