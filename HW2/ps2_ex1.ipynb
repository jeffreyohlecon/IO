{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-agent dynamic discrete choice estimation\n",
    "\n",
    "Conroy Lau\n",
    "\n",
    "This version: December 12, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import random\n",
    "import array\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from numpy.linalg import norm\n",
    "from numpy import ndarray\n",
    "from cyipopt import minimize_ipopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General model setup\n",
    "\n",
    "**Reference: Chapter 2.3.1**\n",
    "\n",
    "The model's primitives are as follows.\n",
    "\n",
    "- Set of alternatives: $\\mathcal{J} \\equiv \\{1, \\ldots, J\\}$.\n",
    "- State variables: $\\mathcal{S}$, with observable component $x_t \\in \\mathcal{X}$ and unobservable component $\\epsilon_t \\equiv \\{\\epsilon_{j,t}\\}_{j \\in \\mathcal{J}}$.\n",
    "- The discount factor: $\\beta$.\n",
    "- Parameter that governs the utility function: $\\theta$.\n",
    "- As a result, the utility of choosing action $j$ at state $s_t$ is given by\n",
    "  $$\n",
    "    u(s_t, j; \\theta) \\equiv \\overline{u}_j(x_t; \\theta) + \\epsilon_{j,t}.\n",
    "  $$\n",
    "- Parameter that governs the transition probabilities: $\\varphi$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rust (1987)\n",
    "\n",
    "To illustrate the estimation methods, we will use the seminal Rust (1987) bus replacement model. \n",
    "\n",
    "We will mostly follow the original model specifications, with a few minor changes as follows.\n",
    "\n",
    "- Set of alternatives: $\\mathcal{J} \\equiv \\{1, 2\\}$.\n",
    "  - Choice 1: maintain bus engine.\n",
    "  - Choice 2: replace bus engine.\n",
    "- State variables:\n",
    "  - Observable state variables: $x_t \\in \\{1, \\ldots, X\\}$ are the bus mileage. In this notebook, we set $X = 10$.\n",
    "  - Unobservable state variables: $\\epsilon_{jt}$ are assumed to follow a mean 0 T1EV distribution for any $j \\in \\mathcal{J}$ and $t$.\n",
    "- Discount factor is assumed to be known. We set this as $\\beta = 0.95$. Note that Rust (1987) uses $\\beta = 0.9999$ in his main specification.\n",
    "- The deterministic component of the utility (i.e., $\\overline{u}_j(x_t; \\theta)$) are parameterized as\n",
    "  - Choice 1: $\\overline{u}_1(x_t; \\theta) = \\theta_1 x_t$.\n",
    "  - Choice 2: $\\overline{u}_2(x_t; \\theta) = \\theta_2$.\n",
    "  - We can interpret $\\theta_1$ as the maintenance cost and $\\theta_2$ as the replacement cost.\n",
    "- The state transition matrix are given as follows.\n",
    "  - When choice 1 is chosen, the transition matrix follows a multinomial distribution with $\\varphi_1 = 0.3$ and $\\varphi_2 = 0.6$. The transition matrix is given by:\n",
    "    $$\n",
    "    \\begin{pmatrix}\n",
    "        \\varphi_1 & \\varphi_2 & 1 - \\varphi_1 - \\varphi_2 & 0 & 0 & \\cdots & 0 & 0 \\\\\n",
    "        0 & \\varphi_1 & \\varphi_2 & 1 - \\varphi_1 - \\varphi_2 & 0 & \\cdots & 0 & 0\\\\\n",
    "        0 & 0 & \\varphi_1 & \\varphi_2 & 1 - \\varphi_1 - \\varphi_2 & \\cdots & 0 & 0 \\\\\n",
    "        0 & 0 & 0 & 0 & 0 & \\cdots & 0 & 0 \\\\\n",
    "        \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\ \n",
    "        0 & 0 & 0 & 0 & 0 & \\cdots & \\varphi_1 & 1 - \\varphi_1 \\\\ \n",
    "        0 & 0 & 0 & 0 & 0 & \\cdots & 0 & 1\n",
    "    \\end{pmatrix}\n",
    "    $$\n",
    "  - When choice 2 is chosen, the states are reset to the initial state.\n",
    "    $$\n",
    "        \\begin{pmatrix}\n",
    "            1 & 0 & 0 & \\cdots & 0 \\\\\n",
    "            1 & 0 & 0 & \\cdots & 0 \\\\\n",
    "            \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "            1 & 0 & 0 & \\cdots & 0 \n",
    "        \\end{pmatrix}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primitive\n",
    "\n",
    "The object `dgp` stores the model primitives. \n",
    "\n",
    "Since we parameterize the utility functions completely by $\\theta$, the object is going to store $\\theta$ instead of the entire vector of utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dgp:\n",
    "    \"\"\"Creates the primitives of the dynamic discrete choice model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        β : `float`\n",
    "            The discount factor.\n",
    "        u : `nd_array`\n",
    "            A matrix of utility over all the states and choices.\n",
    "        f : `nd_array`\n",
    "            Transition matrices for all the actions.\n",
    "        J : `int`\n",
    "            Number of actions.\n",
    "        dx : `int`\n",
    "            Number of states.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        β: float,\n",
    "        u: ndarray,\n",
    "        F: ndarray,\n",
    "        dx: int,\n",
    "        J: int):\n",
    "        \n",
    "        self.β = β\n",
    "        self.u = u\n",
    "        self.F = F\n",
    "        self.dx = dx\n",
    "        self.J = J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the primitive object one-by-one. First, set $\\beta = 0.9$, $\\theta = (-0.2, 5)$, $|\\mathcal{X}| = 10$ and $|\\mathcal{J}| = 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "β = 0.95\n",
    "θ = [-0.2, 5]\n",
    "dx = 10\n",
    "J = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can let `utility` be the deterministic part of the utility function that depends on our pre-defined parameters $\\theta$, as well as the choice and state. Since the deterministic part of the utility is completely characterized by $\\theta$, $x$, and $a$, we can compute them all in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility(\n",
    "    x: int, \n",
    "    a: int,\n",
    "    θ: list):\n",
    "    \"\"\"Calculates the utility at a given action and state.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            x : `int`\n",
    "                State.\n",
    "            a : `int`\n",
    "                Action.\n",
    "            θ : `list`\n",
    "                Utility parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    if a == 0:\n",
    "        u = x * θ[0] + θ[1]\n",
    "    elif a == 1:\n",
    "        u = 0\n",
    "        \n",
    "    return u\n",
    "\n",
    "def utility_matrix(\n",
    "    dx: int,\n",
    "    J: int,\n",
    "    θ: list):\n",
    "    \"\"\"Returns the matrix of utilites over all states and choices.\n",
    "        \n",
    "        Each row corresponds to a state.\n",
    "        \n",
    "        Each column corresponds to an action.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            dx : `int`\n",
    "                Number of states.\n",
    "            J : `int`\n",
    "                Number of actions.\n",
    "            θ: `list`\n",
    "                Utility parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    umat = np.zeros((dx, J))\n",
    "    \n",
    "    for a in range(J):\n",
    "        for x in range(dx):\n",
    "            umat[x, a] = utility(x, a, θ)\n",
    "            \n",
    "    return umat\n",
    "\n",
    "umat = utility_matrix(dx, J, θ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create the transition matrix, i.e., $\\mathrm{Pr}[dx_{t+1}|x_t, a_t = j, \\varphi]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition(\n",
    "    f: list,\n",
    "    dx: int):\n",
    "    \"\"\"Creates the transition matrices.\n",
    "        \n",
    "       This function creates the transition matrices for both actions.\n",
    "       The parameter `f` is only relevant for constructing the \n",
    "       transition matrix for the action j = 0.\n",
    "       \n",
    "       Parameters\n",
    "       ----------\n",
    "           f : `list`\n",
    "               Parameters for the multinomial distribution for j = 0.\n",
    "           dx : `int`\n",
    "               Number of states.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the two matrices\n",
    "    F0 = np.zeros((dx, dx))\n",
    "    F1 = copy.copy(F0)\n",
    "    \n",
    "    # Transition matrix for maintaining the engine\n",
    "    for i in range(dx):\n",
    "        if i < dx - 2:\n",
    "            F0[i, i] = f[0]\n",
    "            F0[i, i + 1] = f[1]\n",
    "            F0[i, i + 2] = 1 - f[0] - f[1]\n",
    "        elif i == dx - 2:\n",
    "            F0[i, i] = f[0]\n",
    "            F0[i, i + 1] = 1 - f[0]\n",
    "        else:\n",
    "            F0[i, i] = 1\n",
    "    \n",
    "    # Transition matrix for replacing the engine\n",
    "    F1[:, 0] = 1\n",
    "        \n",
    "    return F0, F1\n",
    "\n",
    "f = [0.3, 0.6]\n",
    "F = transition(f, dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the primitive objects defined, we can pass them to the `dgp` object as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primitive = dgp(β, umat, F, dx, J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bellman equation representation\n",
    "\n",
    "**Reference: chapter 2.3.1.3**\n",
    "\n",
    "- Let $\\mathrm{Pr}[dx_{t+1}|x_t, a_t = j, \\varphi]$ be the transition probability.\n",
    "- Let $\\overline{v}_j(x_t; \\theta, \\varphi)$ be the deterministic part of the value function for choosing choice $j$ at state $x_t$. Then, we can write\n",
    "  $$\n",
    "    \\overline{v}_j(x_t; \\theta, \\varphi)\n",
    "    = \\overline{u}_j(x_t; \\theta) + \n",
    "        \\beta \\int \n",
    "            \\ln \\left( \\sum_{k \\in \\mathcal{J}}\n",
    "                \\exp\\{\\overline{v}_k(x_{t+1}; \\theta, \\varphi)\\}\n",
    "                \\right) \\mathrm{Pr}[dx_{t+1}|x_t, a_t = j, \\varphi].\n",
    "  $$\n",
    "- The function `csvf_state` codes the choice-specific value function at state `x` with the given vector of value functions `V`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed point representation\n",
    "\n",
    "\n",
    "- Let $\\overline{w}(x_t; \\theta, \\varphi) \\equiv \\ln(\\sum_{k \\in \\mathcal{J}} \\exp\\{\\overline{v}_k(x_k; \\theta, \\varphi)\\})$.\n",
    "- The fixed-point equation can be written as follows:\n",
    "  $$\n",
    "      \\begin{pmatrix}\n",
    "          \\overline{v}_j(1; \\theta, \\varphi) \\\\ \n",
    "          \\vdots \\\\\n",
    "          \\overline{v}_j(X; \\theta, \\varphi)\n",
    "      \\end{pmatrix}\n",
    "      = \n",
    "      \\begin{pmatrix}\n",
    "          \\overline{u}_j(1; \\theta) \\\\ \n",
    "          \\vdots \\\\ \n",
    "          \\overline{u}_j(X; \\theta)\n",
    "      \\end{pmatrix}\n",
    "      + \\beta \\mathbf{P}[x_{t+1} | x_t, a_t; \\varphi]\n",
    "      \\begin{pmatrix}\n",
    "          \\overline{w}(1; \\theta, \\varphi) \\\\ \n",
    "          \\vdots \\\\ \n",
    "          \\overline{w}(X; \\theta, \\varphi)\n",
    "      \\end{pmatrix},\n",
    "  $$\n",
    "  for each $j \\in \\mathcal{J}$.\n",
    "- The above is a fixed-point equation. For a given guess of $\\{\\overline{w}(x; \\theta, \\varphi)\\}_{x \\in \\mathcal{X}}$, one can update $\\{\\overline{v}_j(x; \\theta, \\varphi)\\}_{j \\in \\mathcal{J}, x \\in \\mathcal{X}}$, and then update $\\{\\overline{w}(x; \\theta, \\varphi)\\}_{x \\in \\mathcal{X}}$. One can update this via the fixed point iteration procedure.\n",
    "- The function `vf` computes $\\{\\overline{w}(x; \\theta, \\varphi)\\}_{x \\in \\mathcal{X}}$ for a given of $\\{\\overline{v}_j(x; \\theta, \\varphi)\\}_{j \\in \\mathcal{J}, x \\in \\mathcal{X}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvf_state(dgp, V, x):\n",
    "    \"\"\"Choice-specific value function at a particular state.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            dgp : `dgp`\n",
    "                The primitive of the DDC model.\n",
    "            V : `ndarray`\n",
    "                A vector of value function.\n",
    "            x : `int`\n",
    "                State.\n",
    "    \"\"\"\n",
    "    \n",
    "    w = [dgp.u[x, a] + dgp.β * np.matmul(dgp.F[a][x, :], V) for a in range(dgp.J)]\n",
    "    \n",
    "    return w\n",
    "\n",
    "def csvf(dgp, V):\n",
    "    \"\"\"Choice-specific value functions across all states.\n",
    "    \n",
    "        The function stacks the output of `csvf_state` over all states.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            dgp : `dgp`\n",
    "                The primitive of the DDC model.\n",
    "            V : `ndarray`\n",
    "                A vector of value function.\n",
    "    \"\"\"\n",
    "    \n",
    "    wmat = np.zeros((dgp.dx, dgp.J))\n",
    "    \n",
    "    for x in range(dgp.dx):\n",
    "        wmat[x, :] = csvf_state(dgp, V, x)    \n",
    "    \n",
    "    return wmat\n",
    "\n",
    "def vf(w):\n",
    "    \"\"\"Computes the integrated value function.\n",
    "    \n",
    "        This function computes the integrated value function based on the \n",
    "        choice-specific value functions.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            w : `ndarray`\n",
    "                A vector of value functions.\n",
    "    \"\"\"\n",
    "    \n",
    "    wmax = np.amax(w)\n",
    "    v = np.log(np.exp(w[:, 0] - wmax) + np.exp(w[:, 1] - wmax))\n",
    "    v += wmax\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the value functions being coded, we can code the value function iteration procedure that find the fixed point $\\{\\overline{w}(x; \\theta, \\varphi)\\}_{x \\in \\mathcal{X}}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vfi(dgp, ϵ = 1e-8):\n",
    "    \"\"\"Value function iteration.\n",
    "        \n",
    "        Takes the DGP object and returns the fixed-point of the value function equation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            dgp : `dgp`\n",
    "                The primitives of the DDC model.\n",
    "            ϵ : `float`\n",
    "                The tolerance level.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize - construct utility, transition matrices, and value function\n",
    "    V0 = np.zeros(dgp.dx)\n",
    "\n",
    "    # Iterate until convergence\n",
    "    gap = 10000.\n",
    "    iter = 1\n",
    "    while gap > ϵ:\n",
    "        w = csvf(dgp, V0)\n",
    "        V1 = vf(w)\n",
    "        gap = norm(V0 - V1)\n",
    "        V0 = V1\n",
    "        iter += 1\n",
    "        \n",
    "    return V0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the value function using the model primitives as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_true = vfi(primitive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional choice probability\n",
    "\n",
    "- Under the assumption that $\\epsilon_{jt}$ follows a mean 0 T1EV distribution, the conditional choice probability of choosing $j \\in \\mathcal{J}$ at state $x_t \\in \\mathcal{X}$ is\n",
    "  $$\n",
    "        \\mathrm{Pr}[a_t = j | x_t; \\theta, \\varphi]\n",
    "        = \n",
    "        \\frac{\\exp\\{\\overline{v}_j(x_t; \\theta, \\varphi)\\}}{\n",
    "        \\sum_{k\\in \\mathcal{J}} \\exp\\{\\overline{v}_k(x_t; \\theta, \\varphi)\\}}.\n",
    "  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_from_dgp(dgp, V):\n",
    "    \"\"\"Conditional choice probability of maintaining the engine.\n",
    "    \n",
    "        Compute the conditional choice probability for maintaining the engine.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            dgp : `dgp`\n",
    "                The primitives of the DDC model.\n",
    "            V : `ndarray`\n",
    "                A vector of value functions.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute the choice probability and take the difference\n",
    "    w = csvf(dgp, V)\n",
    "    wmax = np.amax(w)\n",
    "    wdifexp = np.exp(w - wmax)\n",
    "    \n",
    "    # Compute the conditional choice probability\n",
    "    prob = np.zeros((dgp.dx, dgp.J))\n",
    "    wsum = np.sum(wdifexp, axis = 1)\n",
    "    for a in range(dgp.J):\n",
    "        prob[:, a] = wdifexp[:, a]/wsum\n",
    "        \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the probability of maintaining the engine as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_true = prob_from_dgp(primitive, v_true)\n",
    "prob_maintain_true = prob_true[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate data\n",
    "\n",
    "With the functions for the value function and the primitives of the models defined, we are able to simulate data from it. \n",
    "\n",
    "Let there be $N$ (independent) buses and $T$ periods. The following function simulates data and stores the results as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(dgp, V, N, T):\n",
    "    \"\"\"Simulate Rust data.\n",
    "    \n",
    "        Draw data with N buses and T periods based on the `dgp` and `ddc` objects.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            dgp : `dgp`\n",
    "                The primitives of the DDC model.\n",
    "            V : `ndarray`\n",
    "                A vector of value functions.\n",
    "            N : `int`\n",
    "                Number of buses.\n",
    "            T : `int`\n",
    "                Number of periods.\n",
    "    \"\"\"\n",
    "    action = [] #np.zeros((N, T - 1))\n",
    "    state = []\n",
    "    ids = []\n",
    "    ts = [] \n",
    "    \n",
    "    for i in range(N):\n",
    "        ai = np.zeros(T)\n",
    "        si = np.zeros(T, dtype = int)\n",
    "        si[0] = 0\n",
    "        ai[0] = None\n",
    "        \n",
    "        for t in range(T - 1):\n",
    "            # Update state\n",
    "            uf = np.random.uniform()\n",
    "            if (t > 0) & (ai[t] == 0) | (t == 0):\n",
    "                st = si[t]\n",
    "                f0 = dgp.F[0][st]\n",
    "                if si[t] < dgp.dx - 2:\n",
    "                    if uf < f0[st]:\n",
    "                        si[t + 1] = si[t]\n",
    "                    elif (uf >= f0[st]) & (uf < (f0[st] + f0[st + 1])):\n",
    "                        si[t + 1] = si[t] + 1\n",
    "                    else:\n",
    "                        si[t + 1] = si[t] + 2\n",
    "                elif si[t] == dgp.dx - 2:\n",
    "                    if uf < f0[st]:\n",
    "                        si[t + 1] = si[t]\n",
    "                    else:\n",
    "                        si[t + 1] = si[t] + 1\n",
    "                else:\n",
    "                    si[t + 1] = si[t]\n",
    "            elif ai[t] == 1:\n",
    "                si[t + 1] = 0\n",
    "                \n",
    "            # Compute utility at this state and choose utiliy-maximizing action\n",
    "            us = csvf_state(dgp, V, int(si[t + 1]))\n",
    "            us += np.random.gumbel(-.577, size = dgp.J)\n",
    "            ai[t + 1] = np.argmax(us)\n",
    "            \n",
    "        # Append data\n",
    "        state = np.concatenate((state, si))\n",
    "        action = np.concatenate((action, ai))\n",
    "        ids = np.concatenate((ids, np.repeat(i + 1, T)))\n",
    "        ts = np.concatenate((ts, range(0, T)))\n",
    "\n",
    "    df = pd.DataFrame({'i': ids, 't': ts, 'action': action, 'state': state})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simulate data with 30 periods and 30 buses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 30\n",
    "T = 30\n",
    "\n",
    "np.random.seed(1)\n",
    "df = draw(primitive, v_true, N, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's estimate the probability of maintaining the engine based on the simulated data. The following function estimates the probability using the simple frequency estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_ccp(data, dgp):\n",
    "    \"\"\"Estimates conditional choice probability of maintaining the engine\n",
    "        This is estimated using the simple frequency estimator.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : `DataFrame`\n",
    "            The data that contains the actions and states.\n",
    "        dgp : `dgp`\n",
    "            The primitives of the DDC model.\n",
    "    \"\"\"\n",
    "    \n",
    "    phat = np.zeros((dgp.dx, dgp.J))\n",
    "    \n",
    "    for x in range(dgp.dx):\n",
    "        data_x = data.loc[(data.t > 0) & (data.state == x)]\n",
    "        for a in range(dgp.J):\n",
    "            phat[x, a] = np.mean(data_x.action == a)\n",
    "    \n",
    "    return phat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phat = estimate_ccp(df, primitive)\n",
    "phat_maintain = phat[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the probability of choosing engine replacement from the simulated data against the probability specified by the model primitives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()  \n",
    "xs = range(primitive.dx)\n",
    "ax.plot(xs, prob_maintain_true, label = 'True')\n",
    "ax.plot(xs, phat_maintain, label = 'Estimated')\n",
    "ax.set_xlabel('State') \n",
    "ax.set_ylabel('Probability of maintaining engine')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation 1: Nested fixed-point algorithm\n",
    "\n",
    "The nested fixed-point algorithm (NFXP) contains two loops. \n",
    "- **Outer loop**: For a given vector of value functions $V$, find $\\widehat\\theta$ that maximizes the likelihood.\n",
    "- **Inner loop**: For a given utility parameter $\\theta$, find $\\widehat{V}$ the fixed-point.\n",
    "\n",
    "Here, we estimate the transition matrix first, and then take it as given when running NFXP. Hence, we will be maximizing the (partial) log-likelihood instead of the full log-likelihood.\n",
    "\n",
    "The function to estimate the transition matrix is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_transition_maintain(data, dgp):\n",
    "    \"\"\"Estimated the transition matrix for maintaining bus engine.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : `DataFrame`\n",
    "            The data that contains the actions and states.\n",
    "        dgp : `dgp`\n",
    "            The primitives of the DDC model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Estimate Δstate for each of the states\n",
    "    data_tmp = copy.copy(data)\n",
    "    data_tmp['state_shift'] = data_tmp.groupby('i')['state'].shift(-1)\n",
    "    data_tmp['state_dif'] = data_tmp['state_shift'] - data_tmp['state']\n",
    "    data_sub = data_tmp.loc[(data_tmp.action == 0) & (data_tmp.t != max(data_tmp.t))]\n",
    "    \n",
    "    # Construct the transition matrix for a = 0\n",
    "    unique_dif = pd.unique(data_sub['state_dif'])\n",
    "    probs = np.zeros(len(unique_dif))\n",
    "    for idu, val in enumerate(unique_dif):\n",
    "        probs[idu] = np.mean(data_sub['state_dif'] == val)\n",
    "        \n",
    "    return probs\n",
    "\n",
    "\n",
    "def estimate_transition(data, dgp):\n",
    "    \"\"\"Estimate the transition matrix based on the data.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : `DataFrame`\n",
    "            The data that contains the actions and states.\n",
    "        dgp : `dgp`\n",
    "            The primitives of the DDC model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Estimate the parameters of the multinomial distribution\n",
    "    maintain_prob = estimate_transition_maintain(data, dgp)\n",
    "    \n",
    "    # Construct the transition matrix\n",
    "    transition_mat = transition(maintain_prob[range(dgp.J)], dgp.dx)\n",
    "    \n",
    "    return transition_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimation procedure is coded as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_nfxp(θ, data, dgp):\n",
    "    \"\"\"The likelihood function for NFXP.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        θ : `list`\n",
    "            The utility parameters.\n",
    "        data : `DataFrame`\n",
    "            The data that contains the actions and states.\n",
    "        dgp : `dgp`\n",
    "            The primitives of the DDC model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get value functions from parameters\n",
    "    dgp_tmp = copy.copy(dgp)\n",
    "    dgp_tmp.u = utility_matrix(dgp.dx, dgp.J, θ)\n",
    "    V = vfi(dgp_tmp)\n",
    "    \n",
    "    # Get the choice probabilities\n",
    "    pr0 = prob_from_dgp(dgp_tmp, V)\n",
    "        \n",
    "    # Compute likelihood of data\n",
    "    l = likelihood(data, dgp_tmp, pr0)\n",
    "    \n",
    "    return l\n",
    "\n",
    "def likelihood(data, dgp, prob):\n",
    "    \"\"\"The likelihood function with the given choice probability\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : `DataFrame`\n",
    "            The data that contains the actions and states.\n",
    "        dgp : `dgp`\n",
    "            The primitives of the DDC model.\n",
    "        prob : `ndarray`\n",
    "            A matrix of choice probabilities.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute likelihood of data\n",
    "    N = int(max(data.i))\n",
    "    T = int(max(data.t))\n",
    "    l = 0.\n",
    "    \n",
    "    for i in range(N):\n",
    "        for t in range(T):\n",
    "            condn = (data.i == i + 1) & (data.t == t + 1)\n",
    "            a = int(data.loc[condn].action)\n",
    "            x = int(data.loc[condn].state)\n",
    "            \n",
    "            # Append the right probability depending on the choice and state\n",
    "            l += np.log(prob[x, a]) \n",
    "            \n",
    "    return -l/(N*T)\n",
    "\n",
    "def nested_fixed_point(data, dgp):\n",
    "    \"\"\"The nested fixed-point algorithm.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : `DataFrame`\n",
    "            The data that contains the actions and states.\n",
    "        dgp : `dgp`\n",
    "            The primitives of the DDC model.\n",
    "    \"\"\"\n",
    "    def ll(x):\n",
    "        return likelihood_nfxp(x, data, dgp)\n",
    "    θ = minimize(ll, [0.1, 0.1])\n",
    "    \n",
    "    return θ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the procedure `nested_fixed_point` takes the transition matrices in `dgp` as given. As a result, we need to estimate the transition matrix using the given data before passing it to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate transition matrix\n",
    "primitive_hat = copy.copy(primitive)\n",
    "primitive_hat.F = estimate_transition(df, primitive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the solution of the NFXP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the parameters\n",
    "nfxp_out = nested_fixed_point(df, primitive_hat)\n",
    "print(nfxp_out.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare the probability using the parameters implied by the NFXP against the true probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "primitive_nfxp = copy.copy(primitive_hat)\n",
    "primitive_nfxp.u = utility_matrix(dx, J, nfxp_out.x)\n",
    "v_nfxp = vfi(primitive_nfxp)\n",
    "p_nfxp = prob_from_dgp(primitive_nfxp, v_nfxp)\n",
    "\n",
    "fig, ax = plt.subplots()  \n",
    "xs = range(primitive.dx)\n",
    "ax.plot(xs, prob_maintain_true, label = 'True')\n",
    "ax.plot(xs, phat_maintain, label = 'Estimated from data')\n",
    "ax.plot(xs, p_nfxp[:, 0], label = 'Estimated from NFXP')\n",
    "ax.set_xlabel('State') \n",
    "ax.set_ylabel('Probability of maintaining engine')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation 2: Conditional choice probability inversion\n",
    "\n",
    "**Reference: Chapter 2.3.2**\n",
    "\n",
    "- Let $\\widehat{\\text{Pr}}[a_t = j|x_t]$ and $\\widehat{v}_j(x_t)$ be the sample analogue of $\\text{Pr}[a_t = j|x_t; \\theta, \\varphi]$ and $\\overline{v}_j(x_t; \\theta, \\varphi)$ respectively. As noted in footnote 20, we do not index the sample analogue by $\\theta$ and $\\varphi$ because we estimate them from data.\n",
    "- Then, the sample analogue of the conditional choice probability can be written as\n",
    "  $$\n",
    "    \\widehat{\\mathrm{Pr}}[a_t = j | x_t]\n",
    "    = \\frac{\\exp(\\widehat{v}_j(x_t))}{\\sum_{k \\in \\mathcal{J}} \\exp(\\widehat{v}_k(x_t))}.\n",
    "  $$\n",
    "- Let $J$ be the reference choice, or outside option, in which we normalize $\\overline{v}_J(x_t; \\theta, \\varphi) = 0$. Then, using the above sample analogue representation, we can write\n",
    "  $$\n",
    "    \\ln \\left(\n",
    "        \\frac{\\widehat{\\text{Pr}}(a_t = j|x_t)}{\\widehat{\\text{Pr}}(a_t = J|x_t)}\n",
    "        \\right)\n",
    "        = \\widehat{v}_j(x_t) - \\underbrace{\\widehat{v}_J(x_t)}_{\\text{$=0$ by normalization}}.\n",
    "  $$\n",
    "- As a result, the maximum-likelihood estimator would proceed with the objective function\n",
    "  $$\n",
    "    \\sum_t \\sum_{j \\in \\mathcal{J}} \n",
    "      \\mathbf{1}(a_t = j|x_t)\n",
    "      \\log \\left\\{\n",
    "        \\frac{\\exp(\\overline{\\widehat{v}}_j(x_t; \\theta, \\varphi))}{\\sum_{k \\in \\mathcal{J}} \\exp( \\overline{\\widehat{v}}_k(x_t; \\theta, \\varphi))}\n",
    "      \\right\\}\n",
    "  $$\n",
    "  where\n",
    "  $$\n",
    "    \\overline{\\widehat{v}}_j(x_t; \\theta, \\varphi)\n",
    "      - \\overline{\\widehat{v}}_J(x_t; \\theta, \\varphi)\n",
    "      = \\overline{u}_j(x_t; \\theta) - \\overline{u}_J(x_t; \\theta)\n",
    "      + \\beta \\int \\ln \\left(\n",
    "          \\sum_{k \\in \\mathcal{J}}\n",
    "              \\exp(\\widehat{v}_k(x_{t+1}))\n",
    "          \\right)\n",
    "          \\left\\{\n",
    "            \\mathrm{Pr}(dx_{t+1}|x_t, a_t = j, \\varphi)\n",
    "            - \\mathrm{Pr}(dx_{t+1}|x_t, a_t = J, \\varphi)\n",
    "          \\right\\}.\n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function estimates $\\widetilde{v}_a(x)$ based on the choice probability being estimated from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvf_from_ccp(dgp, phat):\n",
    "    \"\"\"Estimates choice-specific value function from choice probabilities.\n",
    "    \n",
    "        The choice-specific value function of the last action is normalized to 0.\n",
    "                \n",
    "        Parameters\n",
    "        ----------\n",
    "        dgp : `dgp`\n",
    "            The primitives of the DDC model.\n",
    "        phat : `ndarray`\n",
    "            The matrix of estimated choice probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    # implement this function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above function, one can implement the two-step method by maximizing the likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_two_step_ccp(θ, data, dgp, phat):\n",
    "    \"\"\"The likelihood function for the two-step method.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        θ : `list`\n",
    "            The utility parameters.\n",
    "        data : `DataFrame`\n",
    "            The data that contains the actions and states.\n",
    "        dgp : `dgp`\n",
    "            The primitives of the DDC model.\n",
    "        phat : `ndarray`\n",
    "            The matrix of estimated choice probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    # implement this function\n",
    "    \n",
    "def two_step_ccp(data, dgp):\n",
    "    \"\"\"The two-step CCP approach.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : `DataFrame`\n",
    "            The data that contains the actions and states.\n",
    "        dgp : `dgp`\n",
    "            The primitives of the DDC model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # implement this function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation 3: Nested pseudo-likelihood\n",
    "\n",
    "**Reference: chapter 2.3.3**\n",
    "\n",
    "- Consider a slightly different notion of value function here together with the assumption that the error term follows a mean-0 T1EV distribution:\n",
    "  $$\n",
    "    \\overline{\\overline{v}}(x_t; \\theta, \\varphi)\n",
    "    = \\sum_{j \\in \\mathcal{J}}\n",
    "        \\text{Pr}(a_t = j|x_t; \\theta, \\varphi)\n",
    "        \\left\\{\n",
    "            \\overline{u}_j(x_t; \\theta) \n",
    "            - \\ln \\mathrm{Pr}(a_t = j|x_t; \\theta, \\varphi)\n",
    "            + \\beta \\sum_{x' \\in \\mathcal{X}}\n",
    "                \\overline{v}(x_{t+1} = x'; \\theta, \\varphi)\n",
    "                \\text{Pr}(x_{t+1} = x'|x_t, a_t = j; \\varphi)\n",
    "        \\right\\}.\n",
    "  $$\n",
    "\n",
    "- By stacking the terms over the states and actions, we obtain a matrix equation where\n",
    "  $$\n",
    "    \\overline{\\overline{v}}(x_t; \\theta, \\varphi)\n",
    "    = [\\mathbf{I} - \\beta \\mathbf{P}(x_{t+1}|x_t; \\theta, \\varphi)]^{-1}\n",
    "    \\mathbf{w}(a_t, x_t; \\theta, \\varphi),\n",
    "  $$\n",
    "  where\n",
    "    - $\\mathbf{w}(a_t, x_t; \\theta, \\varphi)\n",
    "        := \\begin{pmatrix}\n",
    "            \\mathbf{p}(a_t|1; \\theta, \\varphi)'(\\overline{\\mathbf{u}}(x_t = 1; \\theta) - \\ln \\mathbf{p}(a_t|1; \\theta, \\varphi) \\\\ \n",
    "            \\mathbf{p}(a_t|2; \\theta, \\varphi)'(\\overline{\\mathbf{u}}(x_t = 2; \\theta) - \\ln \\mathbf{p}(a_t|2; \\theta, \\varphi) \\\\ \n",
    "            \\vdots \\\\\n",
    "            \\mathbf{p}(a_t|X; \\theta, \\varphi)'(\\overline{\\mathbf{u}}(x_t = X; \\theta) - \\ln \\mathbf{p}(a_t|X; \\theta, \\varphi) \n",
    "        \\end{pmatrix}$.\n",
    "    - $\\mathbf{p}(a_t|1, \\theta, \\varphi)\n",
    "          :=\n",
    "          \\begin{pmatrix}\n",
    "              \\text{Pr}(1|1; \\theta, \\varphi) \\\\ \n",
    "              \\text{Pr}(2|1; \\theta, \\varphi) \\\\\n",
    "              \\vdots \\\\ \n",
    "              \\text{Pr}(J|1; \\theta, \\varphi)\n",
    "          \\end{pmatrix}$.\n",
    "    - $\\mathbf{P}(x_{t+1}|1, a_t; \\varphi)\n",
    "          :=\n",
    "          \\begin{pmatrix}\n",
    "             \\text{Pr}(1|1,1;\\varphi) & \n",
    "             \\text{Pr}(2|1,1;\\varphi) & \n",
    "             \\cdots & \n",
    "             \\text{Pr}(X|1,1;\\varphi) \\\\ \n",
    "             \\text{Pr}(1|1,2;\\varphi) & \n",
    "             \\text{Pr}(2|1,2;\\varphi) & \n",
    "             \\cdots & \n",
    "             \\text{Pr}(X|1,2;\\varphi) \\\\\n",
    "             \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "             \\text{Pr}(1|1,J;\\varphi) & \n",
    "             \\text{Pr}(2|1,J;\\varphi) & \n",
    "             \\cdots & \n",
    "             \\text{Pr}(X|1,J;\\varphi) \n",
    "          \\end{pmatrix}\n",
    "          $.\n",
    "- The $K$-stage policy iteration estimator works as follows. Let $\\mathbf{P}^{K-1}(a_t|x_t; \\theta, \\widehat{\\varphi})$ be the guess of $\\mathbf{P}$ in the $(K-1)$-th step. With the given guess, we want to obtain\n",
    "  $$\n",
    "    \\widehat{\\theta}^K\n",
    "    = \\text{arg max}_{\\theta} \\prod_i\n",
    "        \\mathcal{L}_i\\left(\n",
    "            \\Psi(\n",
    "                \\mathbf{P}^{K-1}(a_t|x_t; \\theta, \\widehat\\varphi)\n",
    "            )\n",
    "        \\right),\n",
    "  $$\n",
    "  where $\\mathcal{L}_i(\\cdot)$ denotes the likelihood induced by the argument. The second step is to update $\\mathbf{P}$ via\n",
    "  $$\n",
    "    \\mathbf{P}^K(a_t|x_t;\\theta,\\widehat{\\varphi})\n",
    "    = \\Psi(\\mathbf{P}^{K-1}(a_t|x_t; \\widehat{\\theta}^K, \\widehat{\\varphi}).\n",
    "  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_unconditional_transition(dgp, phat):\n",
    "    \"\"\"Estimate the unconditional transition matrix.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        dgp : `dgp`\n",
    "            The primitives of the DDC model.\n",
    "        phat : `ndarray`\n",
    "            The matrix of estimated choice probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    P = np.zeros((dgp.dx, dgp.dx))\n",
    "    for a in range(dgp.J):\n",
    "        P += dgp.F[a] * np.transpose([phat[:, a] for i in range(dgp.dx)])# Note: this is incorrect???\n",
    "        \n",
    "    return P\n",
    "\n",
    "def nested_pseudo_likelihood_k(dgp, phat):\n",
    "    \"\"\"Step k of the nested pseudo likelihood method.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        dgp : `dgp`\n",
    "            The primitives of the DDC model.\n",
    "        phat : `ndarray`\n",
    "            The matrix of estimated choice probabilities.\n",
    "    \"\"\"\n",
    "        \n",
    "    # Get the \"w\" function\n",
    "    what = np.sum(phat * (dgp.u - np.log(phat)), axis = 1)\n",
    "    \n",
    "    # Compute \\bar{V} for the value function\n",
    "    I = np.eye(dgp.dx)\n",
    "    P = estimate_unconditional_transition(dgp, phat)\n",
    "    inv_factor = np.linalg.inv(I - dgp.β * P)\n",
    "    vbar = inv_factor @ what\n",
    "    \n",
    "    # Recover the choice-specific value function\n",
    "    pnew = prob_from_dgp(dgp, vbar)\n",
    "    \n",
    "    return pnew\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood for the nested pseudo likelihood method uses the updated $\\widehat P^K$ to construct an updated $\\widehat V^K$, which is subsequently used to construct the choice probability in the objective. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_npl(θ, data, dgp, phat):\n",
    "    \"\"\"The likelihood function for the two-step method.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        θ : `list`\n",
    "            The utility parameters.\n",
    "        data : `DataFrame`\n",
    "            The data that contains the actions and states.\n",
    "        dgp : `dgp`\n",
    "            The primitives of the DDC model.\n",
    "        phat : `ndarray`\n",
    "            The matrix of estimated choice probabilities.\n",
    "    \"\"\"\n",
    "    # Get the utility function based on the parameters\n",
    "    dgp_tmp = copy.copy(dgp)\n",
    "    dgp_tmp.u = utility_matrix(dgp.dx, dgp.J, θ)\n",
    "    \n",
    "    # Get the probability\n",
    "    pk = nested_pseudo_likelihood_k(dgp_tmp, phat)\n",
    "        \n",
    "    # Compute likelihood of data\n",
    "    l = likelihood(data, dgp_tmp, pk)\n",
    "    \n",
    "    return l\n",
    "\n",
    "def nested_pseudo_likelihood(data, dgp, phat, K):\n",
    "    \"\"\"Run the nested pseudo likelihood method with K iterations.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : `DataFrame`\n",
    "            The data that contains the actions and states.\n",
    "        dgp : `dgp`\n",
    "            The primitives of the DDC model.\n",
    "        phat : `ndarray`\n",
    "            The matrix of estimated choice probabilities.\n",
    "        K : `int`\n",
    "            The number of iterations for the nested pseudo likelihood method.\n",
    "    \"\"\"\n",
    "    \n",
    "    pk = copy.copy(phat)\n",
    "    dgpk = copy.copy(dgp)\n",
    "    \n",
    "    for i in range(K):\n",
    "        \n",
    "        def ll(x):\n",
    "            return likelihood_npl(x, data, dgpk, pk)\n",
    "        θiter = minimize(ll, [0.1, 0.1]).x\n",
    "        \n",
    "        dgpk.u = utility_matrix(dgp.dx, dgp.J, θiter)\n",
    "        \n",
    "        pk = nested_pseudo_likelihood_k(dgpk, pk)\n",
    "        \n",
    "        if i == K - 1:\n",
    "            return pk, θiter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the result when we iterate it for $K=10$ times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K = 10\n",
    "npl_out = nested_pseudo_likelihood(df, primitive_hat, phat, 10)\n",
    "npl_out[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation 4: MPEC\n",
    "\n",
    "**Reference: chapter 2.3.1.4**\n",
    "\n",
    "The problem can be implemented as a constrained optimization problem, where we maximize the likelihood subject to the value functions as constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpec(data, dgp):\n",
    "    # Initial parameters\n",
    "    dx = dgp.dx + 2\n",
    "    \n",
    "    # Define objective\n",
    "    def mpec_objective(x):\n",
    "        θ = x[range(2)]\n",
    "        v = x[range(2, dx)]\n",
    "        \n",
    "        dgp_tmp = copy.copy(dgp)\n",
    "        dgp_tmp.u = utility_matrix(dgp.dx, dgp.J, θ)\n",
    "\n",
    "        prob = prob_from_dgp(dgp_tmp, v)\n",
    "        ll = likelihood(data, dgp, prob)\n",
    "        return ll\n",
    "    \n",
    "    # Define equality constraints\n",
    "    def mpec_value_constraints(x):\n",
    "        v = x[range(2, dx)]\n",
    "        return v - vf(csvf(dgp, v))\n",
    "    \n",
    "    # Define lower bound on value functions\n",
    "    def mpec_lb_constraint(x):\n",
    "        v = x[range(2, dx)]\n",
    "        return v\n",
    "        \n",
    "    # Dictionary of constraints\n",
    "    c = [ {'type': 'eq', 'fun': mpec_value_constraints},\n",
    "          {'type': 'ineq', 'fun': mpec_lb_constraint}]\n",
    "        \n",
    "    # Initial point\n",
    "    x0 = np.concatenate((np.array([.1, .1]), np.zeros(dgp.dx)))\n",
    "    \n",
    "    return minimize_ipopt(mpec_objective, \\\n",
    "                          x0 = x0, \\\n",
    "                          constraints = c,\n",
    "                          options = {\"acceptable_tol\": 1e-8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = mpec(df, primitive_hat)\n",
    "print(r.x[range(2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradients can be passed explicitly to the above solver to reduce computational time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Finally, let's collect everything in one function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_ddc(data, dgp, method, K):\n",
    "    \"\"\"Solves a DDC model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : `DataFrame`\n",
    "            The data that contains the actions and states.\n",
    "        dgp : `dgp`\n",
    "            The primitives of the DDC model.\n",
    "        method : `string`\n",
    "            The solution method.\n",
    "        K : `int`\n",
    "            The number of iterations for the nested pseudo likelihood method.\n",
    "            This argument is used only when we use the \"npl\" method.\n",
    "    \"\"\"\n",
    "    \n",
    "    if method == \"nfxp\":\n",
    "        out = nested_fixed_point(data, dgp)\n",
    "    elif method == \"two step\":\n",
    "        out = two_step_ccp(data, dgp)\n",
    "    elif method == \"npl\":\n",
    "        phat = estimate_ccp(data, dgp)\n",
    "        out = nested_pseudo_likelihood(data, dgp, phat, K)\n",
    "    elif method == \"mpec\":\n",
    "        out = mpec(data, dgp)\n",
    "    return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
