{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please comment your code clearly, as the clarity of your code will also\n",
    "# be evaluated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1\n",
    "\n",
    "\n",
    " # unlike in YG's example, no $\\Pi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_individual_shares(delta, X, Gamma, v_draws, by_market):\n",
    "    \"\"\"\n",
    "    Returns a dictionary keyed by market_id,\n",
    "    where each value is a 2D array of shape (num_products_in_mkt, n_draws)\n",
    "    containing the shares s_{i,j,t} for each product j and draw i.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : array of shape (N,)\n",
    "        The mean-utility for each product in the full dataset (already solved via contraction).\n",
    "    X : array (N x 2)\n",
    "        The observables [p, x] for each product.\n",
    "    Gamma : 2x2 array\n",
    "        Current random-coeff parameter matrix.\n",
    "    v_draws : (n_draws x 2)\n",
    "        The taste‐shock draws for [price, x].\n",
    "    by_market : array of shape (N,)\n",
    "        Market IDs labeling each row of (delta, X).\n",
    "    \"\"\"\n",
    "    n_draws = v_draws.shape[0]\n",
    "    # random coefficients (n_draws x 2)\n",
    "    rc = (Gamma @ v_draws.T).T\n",
    "    \n",
    "    unique_mkts = np.unique(by_market)\n",
    "    s_by_market = {}\n",
    "\n",
    "    for m_id in unique_mkts:\n",
    "        idx = (by_market == m_id)\n",
    "        delta_m = delta[idx]               # (#products_in_market,)\n",
    "        X_m     = X[idx, :]               # (#products_in_market, 2)\n",
    "        \n",
    "        # utilities by draw => (num_products_in_mkt, n_draws)\n",
    "        mu = X_m @ rc.T\n",
    "        util = delta_m[:, None] + mu\n",
    "        \n",
    "        exp_util = np.exp(util)\n",
    "        denom    = exp_util.sum(axis=0)   # shape (n_draws,)\n",
    "        s_ij     = exp_util / denom       # shape (#products_in_mkt, n_draws)\n",
    "        \n",
    "        s_by_market[m_id] = s_ij\n",
    "    \n",
    "    return s_by_market\n",
    "import numpy as np\n",
    "\n",
    "def compute_elasticities_for_one_market(s_ij, prices, shares):\n",
    "    \"\"\"\n",
    "    Compute the JxJ elasticity matrix for a single market.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    s_ij : 2D array (J x n_draws)\n",
    "        The *individual-draw* shares for each of the J products (excluding outside good if desired).\n",
    "    prices : 1D array (J,)\n",
    "        Observed prices p_j,t for each of the J products in this market.\n",
    "    shares : 1D array (J,)\n",
    "        Observed shares s_j,t for each product (the average across i, or from your dataframe).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    E : 2D array (J x J)\n",
    "        The elasticity matrix.\n",
    "    \"\"\"\n",
    "    J, n_draws = s_ij.shape\n",
    "    E = np.zeros((J, J))\n",
    "\n",
    "    # For convenience, compute the average across draws for each product:\n",
    "    # But typically you already have \"shares\" from the data or from predict_shares(...).\n",
    "    # Here we just confirm that shares ~ np.mean(s_ij, axis=1).\n",
    "    # We'll use the given 'shares' argument, but you could check consistency.\n",
    "    \n",
    "    for j in range(J):\n",
    "        for k in range(J):\n",
    "            # derivative wrt p_k:\n",
    "            if j == k:\n",
    "                # own derivative: mean_i [ s_ij * (1 - s_ij) ]\n",
    "                deriv = np.mean(s_ij[j,:] * (1.0 - s_ij[j,:]))\n",
    "                # elasticity = - (p_j / s_j) * deriv\n",
    "                E[j,k] = - (prices[j] / shares[j]) * deriv\n",
    "            else:\n",
    "                # cross derivative: mean_i [ s_ij * s_ik ]\n",
    "                deriv = np.mean(s_ij[j,:] * s_ij[k,:])\n",
    "                # elasticity = (p_k / s_j) * deriv\n",
    "                E[j,k] = (prices[k] / shares[j]) * deriv\n",
    "    return E\n",
    "def compute_average_elasticities(\n",
    "    df_all,        # your full dataframe with an outside good included\n",
    "    delta, X, Gamma,  # final parameter estimates\n",
    "    v_draws, by_market\n",
    "):\n",
    "    \"\"\"\n",
    "    For each market t, compute the JxJ elasticity matrix, then\n",
    "    take the simple average across all t (elementwise).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    E_avg : 2D array (J x J)\n",
    "        The average elasticity matrix across markets.\n",
    "    \"\"\"\n",
    "    # 1) Get s_{i,j,t} for each market from the final delta\n",
    "    s_dict = predict_individual_shares(delta, X, Gamma, v_draws, by_market)\n",
    "\n",
    "    # We'll store elasticity matrices for each market in a list\n",
    "    E_list = []\n",
    "    \n",
    "    unique_mkts = df_all[\"market\"].unique()\n",
    "    \n",
    "    for m_id in unique_mkts:\n",
    "        # subset the dataframe to market m_id\n",
    "        df_m = df_all[df_all[\"market\"] == m_id].copy()\n",
    "        # drop the outside good if \"choice=0\" so we get just inside goods\n",
    "        df_m = df_m[df_m[\"choice\"] > 0]\n",
    "        df_m.sort_values(\"choice\", inplace=True)\n",
    "        \n",
    "        # prices and shares (observed) for the inside goods\n",
    "        p_m = df_m[\"p\"].values\n",
    "        s_m = df_m[\"shares\"].values\n",
    "        \n",
    "        # s_ij for this market (the draws-based matrix)\n",
    "        s_ij = s_dict[m_id]\n",
    "        \n",
    "        # also drop row 0 if that corresponds to the outside good:\n",
    "        # (depends on how you stored them, typically row 0 is outside good)\n",
    "        # you can find the index by  (df_m[\"choice\"]==0) etc. \n",
    "        # but if you sorted by choice, and outside good is choice=0, \n",
    "        # that row might be at the front. So let's just do the same filtering:\n",
    "        # We want s_ij only for inside products:\n",
    "        outside_mask = (df_all[\"market\"] == m_id) & (df_all[\"choice\"] == 0)\n",
    "        n_outside = outside_mask.sum()\n",
    "        # so skip the first 'n_outside' rows if indeed outside good was at the top\n",
    "        s_ij_inside = s_ij[n_outside:,:]  \n",
    "        \n",
    "        # Now compute the JxJ for this market\n",
    "        E_m = compute_elasticities_for_one_market(s_ij_inside, p_m, s_m)\n",
    "        E_list.append(E_m)\n",
    "    \n",
    "    # Convert to 3D array to average\n",
    "    # (assuming all markets have the same # of inside products J)\n",
    "    E_stack = np.stack(E_list, axis=2)  # shape (J, J, T)\n",
    "    E_avg = np.mean(E_stack, axis=2)    # shape (J, J)\n",
    "    \n",
    "    return E_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Reading CSV and ensuring each market has an outside good row...\n",
      ">>> Building first-stage weighting matrix W1 = (Z'Z)^-1 ...\n",
      ">>> Starting FIRST pass GMM optimization...\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 310 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 310 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 310 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 310 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 310 iterations.\n",
      "beta\n",
      "[-0.40535423 -2.41233908]\n",
      "obj\n",
      "881.4338015082142\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.81434D+02    |proj g|=  8.11640D+01\n",
      ">>> Contraction mapping converged after 366 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 366 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 366 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 366 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 366 iterations.\n",
      "beta\n",
      "[-0.57159361 -2.15067712]\n",
      "obj\n",
      "816.7144232839889\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      "\n",
      "At iterate    1    f=  8.16714D+02    |proj g|=  2.98854D+01\n",
      ">>> Contraction mapping converged after 597 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 597 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 597 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 597 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 597 iterations.\n",
      "beta\n",
      "[-0.80755338 -1.44807302]\n",
      "obj\n",
      "689.7110007834717\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      "\n",
      "At iterate    2    f=  6.89711D+02    |proj g|=  3.34398D+01\n",
      ">>> Contraction mapping converged after 624 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 624 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 624 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 624 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 624 iterations.\n",
      "beta\n",
      "[-0.82903965 -1.42400278]\n",
      "obj\n",
      "684.4812774750305\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      "\n",
      "At iterate    3    f=  6.84481D+02    |proj g|=  1.95642D+01\n",
      ">>> Contraction mapping converged after 731 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 731 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 731 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 731 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 731 iterations.\n",
      "beta\n",
      "[-0.94475982 -1.30802488]\n",
      "obj\n",
      "678.8084160094398\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      "\n",
      "At iterate    4    f=  6.78808D+02    |proj g|=  1.59322D+01\n",
      ">>> Contraction mapping converged after 1085 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1085 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1085 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1085 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1085 iterations.\n",
      "beta\n",
      "[-1.46560394 -0.83120551]\n",
      "obj\n",
      "665.2179576664804\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      "\n",
      "At iterate    5    f=  6.65218D+02    |proj g|=  4.19640D+00\n",
      ">>> Contraction mapping converged after 1186 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1186 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1186 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1186 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1186 iterations.\n",
      "beta\n",
      "[-1.65458321 -0.67104201]\n",
      "obj\n",
      "663.8360764885294\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      "\n",
      "At iterate    6    f=  6.63836D+02    |proj g|=  2.09944D+00\n",
      ">>> Contraction mapping converged after 1227 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1227 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1227 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1227 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1227 iterations.\n",
      "beta\n",
      "[-1.72101885 -0.61895553]\n",
      "obj\n",
      "663.7086205217515\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      "\n",
      "At iterate    7    f=  6.63709D+02    |proj g|=  5.76152D-01\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      "beta\n",
      "[-1.72687739 -0.61419263]\n",
      "obj\n",
      "663.7059332587312\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      "\n",
      "At iterate    8    f=  6.63706D+02    |proj g|=  1.21868D-01\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      "beta\n",
      "[-1.72658199 -0.61463082]\n",
      "obj\n",
      "663.7058339922169\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      "\n",
      "At iterate    9    f=  6.63706D+02    |proj g|=  1.49957D-02\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      "beta\n",
      "[-1.7262857  -0.61488548]\n",
      "obj\n",
      "663.7058308245055\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      "\n",
      "At iterate   10    f=  6.63706D+02    |proj g|=  5.13555D-04\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      ">>> Contraction mapping converged after 1232 iterations.\n",
      "beta\n",
      "[-1.72626348 -0.61490314]\n",
      "obj\n",
      "663.7058308170024\n",
      "    [FIRST PASS] success=True, params=[ 4.65683700e+00 -1.22243037e-01  1.40885363e-03], obj=663.706\n",
      ">>> Starting contraction mapping to solve for delta_j...\n",
      "\n",
      "At iterate   11    f=  6.63706D+02    |proj g|=  1.93416D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     11     12     14     0     0   1.934D-05   6.637D+02\n",
      "  F =   663.70583081700238     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      ">>> Contraction mapping converged after 1232 iterations.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'compute_average_elasticities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 432\u001b[0m\n\u001b[1;32m    429\u001b[0m df_all \u001b[38;5;241m=\u001b[39m read_data_with_outside_good(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mps1_ex4.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# 2)  Perform the two-step GMM estimation\u001b[39;00m\n\u001b[0;32m--> 432\u001b[0m first_pass,E_avg \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_blp_iterative_gmm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_draws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ml-bfgs-b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_analytic_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== FINAL RESULTS ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[FIRST PASS] success=\u001b[39m\u001b[38;5;124m\"\u001b[39m, first_pass\u001b[38;5;241m.\u001b[39msuccess)\n",
      "Cell \u001b[0;32mIn[77], line 363\u001b[0m, in \u001b[0;36mestimate_blp_iterative_gmm\u001b[0;34m(df, n_draws, method, use_analytic_grad)\u001b[0m\n\u001b[1;32m    359\u001b[0m     Gamma_hat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[res1\u001b[38;5;241m.\u001b[39mx[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    360\u001b[0m                   [res1\u001b[38;5;241m.\u001b[39mx[\u001b[38;5;241m1\u001b[39m],res1\u001b[38;5;241m.\u001b[39mx[\u001b[38;5;241m2\u001b[39m]]])\n\u001b[1;32m    361\u001b[0m     delta_hat \u001b[38;5;241m=\u001b[39m contraction_mapping(s_obs, X, Gamma_hat, v_draws, by_market,\n\u001b[1;32m    362\u001b[0m                                 print_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9999999\u001b[39m)\n\u001b[0;32m--> 363\u001b[0m     E_avg \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_average_elasticities\u001b[49m(\n\u001b[1;32m    364\u001b[0m     df_all, \n\u001b[1;32m    365\u001b[0m     delta_hat, \n\u001b[1;32m    366\u001b[0m     X\u001b[38;5;241m=\u001b[39mdf_all[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues, \n\u001b[1;32m    367\u001b[0m     Gamma\u001b[38;5;241m=\u001b[39mGamma_hat, \n\u001b[1;32m    368\u001b[0m     v_draws\u001b[38;5;241m=\u001b[39mv_draws, \n\u001b[1;32m    369\u001b[0m     by_market\u001b[38;5;241m=\u001b[39mdf_all[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarket\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m    370\u001b[0m )\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;66;03m# ------------------------\u001b[39;00m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;66;03m# 2nd Step: Build W2 using \\hat{x}\\hat{x}' from first pass\u001b[39;00m\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;66;03m# ------------------------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;66;03m# print(f\"    [SECOND PASS] success={res2.success}, \"\u001b[39;00m\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;66;03m#       f\"params={res2.x}, obj={res2.fun:.6g}\")\u001b[39;00m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res1,E_avg\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_average_elasticities' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.sandbox.regression.gmm as gmm\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS\n",
    "\n",
    "##############################################################################\n",
    "# 1. Read Data & Construct Outside Good\n",
    "##############################################################################\n",
    "def read_data_with_outside_good(csv_path):\n",
    "    \"\"\"\n",
    "    Reads a dataset that has columns:\n",
    "        market, choice, shares, p, x, z1, z2, ...\n",
    "    If the outside good (choice=0) is *not* in the CSV, this function\n",
    "    creates a synthetic row for each market with p0=x0=0, share=1-sum(shares_in_market),\n",
    "    and zeros for instruments if needed.\n",
    "    \"\"\"\n",
    "    print(\">>> Reading CSV and ensuring each market has an outside good row...\")\n",
    "    df = pd.read_csv(csv_path).copy()\n",
    "    df.sort_values(by=[\"market\", \"choice\"], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    frames = []\n",
    "    for m in df[\"market\"].unique():\n",
    "        this_mkt = df.loc[df[\"market\"] == m].copy()\n",
    "        outside_row = this_mkt.loc[this_mkt[\"choice\"] == 0]\n",
    "\n",
    "        if outside_row.empty:\n",
    "            sum_inside = this_mkt[\"shares\"].sum()\n",
    "            outside_share = max(0.0, 1.0 - sum_inside)\n",
    "            row_outside = {\n",
    "                \"market\": m,\n",
    "                \"choice\": 0,\n",
    "                \"shares\": outside_share,\n",
    "                \"p\": 0.0,\n",
    "                \"x\": 0.0,\n",
    "            }\n",
    "            # For z1,z2,... set to 0\n",
    "            for c in this_mkt.columns:\n",
    "                if c.startswith(\"z\"):\n",
    "                    row_outside[c] = 0.0\n",
    "            this_mkt = pd.concat([this_mkt, pd.DataFrame([row_outside])],\n",
    "                                 ignore_index=True)\n",
    "\n",
    "        this_mkt.sort_values(\"choice\", inplace=True)\n",
    "        frames.append(this_mkt)\n",
    "\n",
    "    df_out = pd.concat(frames, ignore_index=True)\n",
    "    df_out.sort_values(by=[\"market\", \"choice\"], inplace=True)\n",
    "    df_out.reset_index(drop=True, inplace=True)\n",
    "    return df_out\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 2. Draw (vi) ~ N(0, I)\n",
    "##############################################################################\n",
    "def draw_taste_shocks(n_draws=50, seed=0):\n",
    "    \"\"\"\n",
    "    Return an array of shape (n_draws, 2) of normal(0,1) draws\n",
    "    for random coefficients dimension=2 (e.g., for price & x).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    v = rng.normal(0.0, 1.0, size=(n_draws, 2))\n",
    "    return v\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 3. Predict Shares (Vectorized)\n",
    "##############################################################################\n",
    "def predict_shares(delta, X, Gamma, v_draws, by_market):\n",
    "    \"\"\"\n",
    "    Vectorized share prediction:\n",
    "      s_j = (1/n_draws) sum_{i=1..n_draws} \n",
    "             exp( delta_j + X_j @ (Gamma v_i) )\n",
    "           / sum_{k} exp( delta_k + X_k @ (Gamma v_i) ),\n",
    "    by market.\n",
    "    \"\"\"\n",
    "    n_draws = v_draws.shape[0]\n",
    "    s_pred = np.zeros_like(delta)\n",
    "\n",
    "    # Precompute random coefficients for all draws => shape (n_draws, 2)\n",
    "    rc = (Gamma @ v_draws.T).T  # shape (n_draws, 2)\n",
    "\n",
    "    unique_mkts = np.unique(by_market)\n",
    "    for m_id in unique_mkts:\n",
    "        idx = (by_market == m_id)\n",
    "\n",
    "        delta_m = delta[idx]          # (#products_in_market,)\n",
    "        X_m     = X[idx,:]            # (#products_in_market, 2)\n",
    "\n",
    "        mu = X_m @ rc.T                             # (#products_in_market, n_draws)\n",
    "        util = delta_m[:, None] + mu                # (#products_in_market, n_draws)\n",
    "        exp_util = np.exp(util)\n",
    "\n",
    "        denom = exp_util.sum(axis=0)                # shape (n_draws,)\n",
    "        s_pred[idx] = (exp_util / denom).mean(axis=1)\n",
    "\n",
    "    return s_pred\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 4. Contraction Mapping\n",
    "##############################################################################\n",
    "def contraction_mapping(s_obs, X, Gamma, v_draws, by_market,\n",
    "                       tol=1e-6, max_iter=100000, print_every=500):\n",
    "    \"\"\"\n",
    "    Solves for delta_j subject to s_pred(delta) = s_obs.\n",
    "    Outside good => delta_0=0. We only update inside goods in the iteration.\n",
    "    \"\"\"\n",
    "    print(\">>> Starting contraction mapping to solve for delta_j...\")\n",
    "    outside_idx = np.all(np.isclose(X, 0.0), axis=1)  # index of outside good\n",
    "    inside_idx  = ~outside_idx\n",
    "\n",
    "    s_obs_safe = s_obs.clip(1e-16)\n",
    "    # Initialize delta via log(s_j)\n",
    "    delta = np.log(s_obs_safe)\n",
    "    delta[outside_idx] = 0.0  # delta for outside good set to 0\n",
    "\n",
    "    for iteration in range(max_iter):\n",
    "        if (iteration % print_every == 0) and (iteration > 0):\n",
    "            pct = 100.0 * iteration / max_iter\n",
    "            print(f\"    Contraction iteration: {iteration}/{max_iter} ({pct:.1f}% done)\")\n",
    "\n",
    "        s_pred = predict_shares(delta, X, Gamma, v_draws, by_market)\n",
    "        s_pred_safe = s_pred.clip(1e-16)\n",
    "\n",
    "        delta_new = delta.copy()\n",
    "        delta_new[inside_idx] = (\n",
    "            delta[inside_idx]\n",
    "            + np.log(s_obs_safe[inside_idx])\n",
    "            - np.log(s_pred_safe[inside_idx])\n",
    "        )\n",
    "        delta_new[outside_idx] = 0.0\n",
    "\n",
    "        sup_norm = np.max(np.abs(delta_new - delta))\n",
    "        delta = delta_new\n",
    "        if sup_norm < tol:\n",
    "            print(f\">>> Contraction mapping converged after {iteration+1} iterations.\")\n",
    "            break\n",
    "\n",
    "    return delta\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 5a. GMM Objective\n",
    "##############################################################################\n",
    "def gmm_objective(params, s_obs, X, Z, v_draws, by_market, W):\n",
    "    \"\"\"\n",
    "    Objective = (Z' xi)' W (Z' xi),\n",
    "    where xi = delta - X beta and delta solves the contraction mapping.\n",
    "    \"\"\"\n",
    "    gamma11, gamma21, gamma22 = params\n",
    "    Gamma = np.array([\n",
    "        [gamma11, 0.0],\n",
    "        [gamma21, gamma22]\n",
    "    ])\n",
    "\n",
    "    # Solve for delta\n",
    "    delta = contraction_mapping(s_obs, X, Gamma, v_draws, by_market,\n",
    "                                print_every=9999999)\n",
    "\n",
    "    # 2SLS to get beta\n",
    "    Z_with_const = sm.add_constant(Z, has_constant='add')\n",
    "    iv_model = IV2SLS(endog=delta, exog=X, instrument=Z_with_const)\n",
    "    iv_results = iv_model.fit()\n",
    "    beta = iv_results.params\n",
    "\n",
    "    xi = delta - X @ beta\n",
    "    m = Z.T @ xi\n",
    "    obj = m.T @ W @ m\n",
    "\n",
    "    return obj\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 5b. Helpers for gradient-based GMM\n",
    "##############################################################################\n",
    "def approximate_delta_grad(gamma, s_obs, X, v_draws, by_market,\n",
    "                           h=1e-5):\n",
    "    \"\"\"\n",
    "    Numerically approximate d(delta)/dGamma at the current Gamma.\n",
    "    gamma = [gamma11, gamma21, gamma22]\n",
    "    Returns: ddelta_dgamma, shape (N, 3)\n",
    "    \"\"\"\n",
    "    gamma11, gamma21, gamma22 = gamma\n",
    "    Gamma_base = np.array([[gamma11, 0.0],\n",
    "                           [gamma21, gamma22]])\n",
    "    delta_base = contraction_mapping(s_obs, X, Gamma_base, v_draws, by_market,\n",
    "                                     print_every=9999999)\n",
    "\n",
    "    n = len(delta_base)\n",
    "    ddelta_dgamma = np.zeros((n, 3))\n",
    "\n",
    "    for j in range(3):\n",
    "        step = np.zeros(3)\n",
    "        step[j] = h\n",
    "\n",
    "        Gamma_pert = np.array([\n",
    "            [gamma11 + step[0], 0.0],\n",
    "            [gamma21 + step[1], gamma22 + step[2]]\n",
    "        ])\n",
    "        delta_pert = contraction_mapping(s_obs, X, Gamma_pert, v_draws, by_market,\n",
    "                                         print_every=9999999)\n",
    "        ddelta_dgamma[:, j] = (delta_pert - delta_base) / (step[j])\n",
    "\n",
    "    return ddelta_dgamma\n",
    "\n",
    "def compute_2sls_beta(delta, X, Z):\n",
    "    \"\"\"\n",
    "    Compute 2SLS coefficient vector from model: delta = X beta + error\n",
    "    with instruments Z (including a constant).\n",
    "    \"\"\"\n",
    "    iv_model = gmm.IV2SLS(endog=delta, exog=X, instrument=Z)\n",
    "    results = iv_model.fit()\n",
    "    return results.params\n",
    "\n",
    "def gmm_objective_and_grad(gamma, s_obs, X, Z, v_draws, by_market, W):\n",
    "    \"\"\"\n",
    "    Returns: (objective, gradient wrt gamma),\n",
    "    where gamma = [gamma11, gamma21, gamma22].\n",
    "    \"\"\"\n",
    "    # 1) Build Gamma, solve for delta\n",
    "    gamma11, gamma21, gamma22 = gamma\n",
    "    Gamma = np.array([[gamma11, 0.0],\n",
    "                      [gamma21, gamma22]])\n",
    "    delta = contraction_mapping(s_obs, X, Gamma, v_draws, by_market,\n",
    "                                print_every=9999999)\n",
    "\n",
    "    # 2) Add constant in instruments\n",
    "    ones = np.ones((Z.shape[0], 1))\n",
    "    Z_with_const = np.hstack([ones, Z])\n",
    "\n",
    "    # 3) Compute 2SLS beta\n",
    "    beta_2sls = compute_2sls_beta(delta, X, Z_with_const)\n",
    "\n",
    "    # 4) xi = delta - X beta\n",
    "    xi = delta - X @ beta_2sls\n",
    "\n",
    "    # 5) Evaluate objective\n",
    "    m = Z.T @ xi\n",
    "    obj = m.T @ W @ m\n",
    "\n",
    "    # 6) We need d(delta)/d(gamma)\n",
    "    ddelta_dgamma = approximate_delta_grad(gamma, s_obs, X, v_draws, by_market)\n",
    "\n",
    "    # 7) Then d(beta)/d(gamma)\n",
    "    ZtZ_inv = np.linalg.inv(Z_with_const.T @ Z_with_const)\n",
    "    PZc = Z_with_const @ ZtZ_inv @ Z_with_const.T\n",
    "    XPZX = X.T @ PZc @ X\n",
    "    XPZX_inv = np.linalg.inv(XPZX)\n",
    "    B = XPZX_inv @ (X.T @ PZc)\n",
    "    n = len(delta)\n",
    "    M = np.eye(n) - X @ B  # shape (N, N)\n",
    "\n",
    "    # 8) derivative wrt xi of the objective: g_xi = 2 Z W (Z' xi)\n",
    "    g_xi = 2.0 * (Z @ (W @ (Z.T @ xi)))  # shape (N,)\n",
    "\n",
    "    # 9) gradient wrt gamma\n",
    "    ddelta = M @ ddelta_dgamma  # shape (N,3)\n",
    "    grad_gamma = ddelta.T @ g_xi  # shape (3,)\n",
    "    print(\"beta\")\n",
    "    print(beta_2sls)\n",
    "    print(\"obj\")\n",
    "    print(obj)\n",
    "    return obj, grad_gamma\n",
    "\n",
    "##############################################################################\n",
    "# 5c. Utility: get current xi for a given Gamma (for building W2)\n",
    "##############################################################################\n",
    "def get_xi_for_gamma(gamma, s_obs, X, Z, v_draws, by_market):\n",
    "    \"\"\"\n",
    "    Returns xi (N-vector), plus the final delta and the 2SLS beta,\n",
    "    all given the current gamma = [gamma11, gamma21, gamma22].\n",
    "    \"\"\"\n",
    "    gamma11, gamma21, gamma22 = gamma\n",
    "    Gamma = np.array([[gamma11, 0.0],\n",
    "                      [gamma21, gamma22]])\n",
    "    # Solve for delta\n",
    "    delta = contraction_mapping(s_obs, X, Gamma, v_draws, by_market,\n",
    "                                print_every=9999999)\n",
    "\n",
    "    # 2SLS\n",
    "    Z_with_const = sm.add_constant(Z, has_constant='add')\n",
    "    iv_model = IV2SLS(endog=delta, exog=X, instrument=Z_with_const)\n",
    "    iv_results = iv_model.fit()\n",
    "    beta = iv_results.params\n",
    "\n",
    "    xi = delta - X @ beta\n",
    "    return xi, delta, beta\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 6. Two-Step GMM with Progress Messages (NEW)\n",
    "##############################################################################\n",
    "def estimate_blp_iterative_gmm(df, n_draws=50, method=\"BFGS\", use_analytic_grad=True):\n",
    "    \"\"\"\n",
    "    1) Build Z, initial W1 = (Z'Z)^(-1)\n",
    "    2) Minimize GMM => res1\n",
    "    3) Recompute W => W2 from res1's estimates\n",
    "    4) Minimize => res2\n",
    "    Returns both passes.\n",
    "    \"\"\"\n",
    "    df.sort_values(by=[\"market\",\"choice\"], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    s_obs = df[\"shares\"].values\n",
    "    X = df[[\"p\",\"x\"]].values\n",
    "    z_cols = [c for c in df.columns if c.startswith(\"z\")]\n",
    "    if not z_cols:\n",
    "        raise ValueError(\"No instrument columns found!\")\n",
    "    Z = df[z_cols].values\n",
    "\n",
    "    by_market = df[\"market\"].values\n",
    "\n",
    "    print(\">>> Building first-stage weighting matrix W1 = (Z'Z)^-1 ...\")\n",
    "    ZZ = Z.T @ Z\n",
    "    eye_k = np.eye(ZZ.shape[0])\n",
    "    W1 = np.linalg.inv(ZZ + 1e-12 * eye_k)\n",
    "\n",
    "    # Draw taste shocks\n",
    "    v_draws = draw_taste_shocks(n_draws=n_draws, seed=0)\n",
    "\n",
    "    init_params = np.array([1,1,1])\n",
    "    print(\">>> Starting FIRST pass GMM optimization...\")\n",
    "    #standard devs must be positive. enforced by these bounds.\n",
    "    bounds = [(0, None) if i in [0, 2] else (None, None) \n",
    "             for i in range(len(init_params))]   \n",
    "    # Helper for first pass\n",
    "    if use_analytic_grad:\n",
    "        def obj_grad_fun_1(par):\n",
    "            return gmm_objective_and_grad(\n",
    "                par, s_obs, X, Z, v_draws, by_market, W1\n",
    "            )\n",
    "        res1 = minimize(\n",
    "            obj_grad_fun_1,\n",
    "            init_params,\n",
    "            method=method,\n",
    "            jac=True,\n",
    "            bounds = bounds,\n",
    "            options={\"disp\": True, \"maxiter\": 40}\n",
    "        )\n",
    "    else:\n",
    "        def obj_fun_1(par):\n",
    "            return gmm_objective(\n",
    "                par, s_obs, X, Z, v_draws, by_market, W1\n",
    "            )\n",
    "        res1 = minimize(\n",
    "            obj_fun_1,\n",
    "            init_params,\n",
    "            method=method,\n",
    "            bounds = bounds,\n",
    "            options={\"disp\": True, \"maxiter\": 40}\n",
    "        )\n",
    "\n",
    "    print(f\"    [FIRST PASS] success={res1.success}, \"\n",
    "          f\"params={res1.x}, obj={res1.fun:.6g}\")\n",
    "    #Final values for computing elasticities\n",
    "    Gamma_hat = np.array([[res1.x[0], 0],\n",
    "                  [res1.x[1],res1.x[2]]])\n",
    "    delta_hat = contraction_mapping(s_obs, X, Gamma_hat, v_draws, by_market,\n",
    "                                print_every=9999999)\n",
    "    E_avg = compute_average_elasticities(\n",
    "    df_all, \n",
    "    delta_hat, \n",
    "    X=df_all[[\"p\",\"x\"]].values, \n",
    "    Gamma=Gamma_hat, \n",
    "    v_draws=v_draws, \n",
    "    by_market=df_all[\"market\"].values\n",
    ")\n",
    "    # ------------------------\n",
    "    # 2nd Step: Build W2 using \\hat{x}\\hat{x}' from first pass\n",
    "    # ------------------------\n",
    "    # print(\"\\n>>> Building second-stage weighting matrix W2 ...\")\n",
    "    # gamma_hat_1 = res1.x\n",
    "    # xi_1, _, _ = get_xi_for_gamma(gamma_hat_1, s_obs, X, Z, v_draws, by_market)\n",
    "    # # moment = Z_i * xi_i.  We'll form S = sum_i (Z_i xi_i)(Z_i xi_i)' => (Z' * diag(xi) * Z),\n",
    "    # # typically with a 1/N factor as well. We'll do the simplest approach:\n",
    "\n",
    "    # # shape: (N, K)\n",
    "    # ZX = Z * xi_1.reshape(-1,1)  # elementwise multiply each column of Z by xi\n",
    "    # S_hat = ZX.T @ ZX  # shape (K,K), sum of outer products\n",
    "    # # Optionally scale by 1/N or 1/(N-K).\n",
    "    # N = Z.shape[0]\n",
    "    # S_hat /= N\n",
    "\n",
    "    # # W2 is inverse of S_hat\n",
    "    # # (Add small ridge if needed for invertibility)\n",
    "    # ridge = 1e-12 * np.eye(S_hat.shape[0])\n",
    "    # W2 = np.linalg.inv(S_hat + ridge)\n",
    "\n",
    "    # # 2nd pass optimization\n",
    "    # print(\">>> Starting SECOND pass GMM optimization using W2...\")\n",
    "    # if use_analytic_grad:\n",
    "    #     def obj_grad_fun_2(par):\n",
    "    #         return gmm_objective_and_grad(\n",
    "    #             par, s_obs, X, Z, v_draws, by_market, W2\n",
    "    #         )\n",
    "    #     res2 = minimize(\n",
    "    #         obj_grad_fun_2,\n",
    "    #         res1.x,   #  first pass estimate as initial\n",
    "    #         method=method,\n",
    "    #         jac=True,\n",
    "    #         options={\"disp\": True, \"maxiter\": 10}\n",
    "    #     )\n",
    "    # else:\n",
    "    #     def obj_fun_2(par):\n",
    "    #         return gmm_objective(\n",
    "    #             par, s_obs, X, Z, v_draws, by_market, W2\n",
    "    #         )\n",
    "    #     res2 = minimize(\n",
    "    #         obj_fun_2,\n",
    "    #         res1.x,\n",
    "    #         method=method,\n",
    "    #         options={\"disp\": True, \"maxiter\": 10}\n",
    "    #     )\n",
    "\n",
    "    # print(f\"    [SECOND PASS] success={res2.success}, \"\n",
    "    #       f\"params={res2.x}, obj={res2.fun:.6g}\")\n",
    "\n",
    "    return res1,E_avg#, res2\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 7. Main \n",
    "##############################################################################\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Read data, ensuring outside good rows\n",
    "    df_all = read_data_with_outside_good(\"ps1_ex4.csv\")\n",
    "\n",
    "    # 2)  Perform the two-step GMM estimation\n",
    "    first_pass,E_avg = estimate_blp_iterative_gmm(\n",
    "        df_all,\n",
    "        n_draws=50,\n",
    "        method='l-bfgs-b' ,\n",
    "        use_analytic_grad=True\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== FINAL RESULTS ===\")\n",
    "    print(\"[FIRST PASS] success=\", first_pass.success)\n",
    "    print(\"  params=\", first_pass.x)\n",
    "    print(\"  objective=\", first_pass.fun)\n",
    "    #print(\"[SECOND PASS] success=\", second_pass.success)\n",
    "    #print(\"  params=\", second_pass.x)\n",
    "    #print(\"  objective=\", second_pass.fun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.65683615e+00,  0.00000000e+00],\n",
       "       [-1.22243271e-01,  1.40879983e-03]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gamma = np.array([[first_pass.x[0], 0.00000000e+00],\n",
    "                  [first_pass.x[1],first_pass.x[2]]])\n",
    "Gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.16861230e+01, -5.69266886e-01],\n",
       "       [-5.69266886e-01,  1.49454021e-02]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply Gamma by its transpose\n",
    "Omega = np.dot(Gamma, Gamma.T)\n",
    "Omega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4.2    \n",
    " For each market, compute cross and own product elasticities. Average your results across\n",
    "markets and present them in a J ×J table whose (i, j) element contains the (average) elasticity\n",
    "of product i with respect to an increase in the price of product j. What’s the main difference\n",
    "when compared with the table of elasticities you found in 2.2?\n",
    "\n",
    "\n",
    "see slide 14 of Yonggeun's slides. we need to use the prices, shares, alpha_i (not clear how that maps to here) , and density of q_i (not sure how that maps to here), and density of v_i (assumed above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 look at average price and share for products, across market, using $\\Gamma$, what is driving differences in prices and market shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Average Price, x, and Share by Product}\n",
      "\\label{tab:avg_price_x_share}\n",
      "\\begin{tabular}{rrrr}\n",
      "\\toprule\n",
      "choice & avg_price & avg_x & avg_share \\\\\n",
      "\\midrule\n",
      "0 & 0.0000 & 0.0000 & 0.3848 \\\\\n",
      "1 & 0.0024 & -0.0193 & 0.0988 \\\\\n",
      "2 & 0.0023 & -0.0260 & 0.0891 \\\\\n",
      "3 & 2.0191 & -0.0813 & 0.0430 \\\\\n",
      "4 & 1.7516 & -0.1801 & 0.0393 \\\\\n",
      "5 & 3.5770 & 1.6926 & 0.1517 \\\\\n",
      "6 & 4.4429 & 2.0024 & 0.1932 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Group by product, compute mean for p, x, and shares\n",
    "table = (\n",
    "    df_all\n",
    "    .groupby('choice', as_index=False)\n",
    "    .agg(\n",
    "        avg_price=('p','mean'),\n",
    "        avg_x=('x','mean'),\n",
    "        avg_share=('shares','mean')\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2. Convert to LaTeX\n",
    "latex_table = table.to_latex(\n",
    "    index=False,\n",
    "    float_format=\"%.4f\",    # set decimal precision as needed\n",
    "    caption=\"Average Price, x, and Share by Product\",\n",
    "    label=\"tab:avg_price_x_share\"\n",
    ")\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 PyBLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyblp in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyblp) (2.1.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyblp) (0.5.6)\n",
      "Requirement already satisfied: pyhdfe>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyblp) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyblp) (1.14.1)\n",
      "Requirement already satisfied: sympy>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyblp) (1.13.3)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from patsy>=0.5.1->pyblp) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sympy>=1.1.0->pyblp) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyblp\n",
    "import pyblp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(prices + x, prices + x)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_blp = df_all.copy()\n",
    "df_blp = df_blp.rename(columns={'p': 'prices'})\n",
    "df_blp = df_blp.rename(columns={'choice': 'product_ids'})\n",
    "df_blp = df_blp.rename(columns={'market': 'market_ids'})\n",
    "\n",
    "\n",
    "\n",
    "df_blp = df_blp.rename(columns={'z1': 'demand_instruments0'})\n",
    "df_blp = df_blp.rename(columns={'z2': 'demand_instruments1'})\n",
    "df_blp = df_blp.rename(columns={'z3': 'demand_instruments2'})\n",
    "df_blp = df_blp.rename(columns={'z4': 'demand_instruments3'})\n",
    "df_blp = df_blp.rename(columns={'z5': 'demand_instruments4'})\n",
    "df_blp = df_blp.rename(columns={'z6': 'demand_instruments5'})\n",
    "\n",
    "#drop outside good.\n",
    "df_blp = df_blp[df_blp['product_ids'] != 0]\n",
    "\n",
    "# X1 are things that have homog effects\n",
    "#X2 are (potentially same things) with heterog. effects\n",
    "X1_formulation = pyblp.Formulation('0+ prices + x') # no constant term\n",
    "X2_formulation = pyblp.Formulation('0 + prices + x') # random coefficient for outside good is not a thing in this model.\n",
    "product_formulations = (X1_formulation,X2_formulation)\n",
    "product_formulations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_ids</th>\n",
       "      <th>product_ids</th>\n",
       "      <th>shares</th>\n",
       "      <th>prices</th>\n",
       "      <th>x</th>\n",
       "      <th>demand_instruments0</th>\n",
       "      <th>demand_instruments1</th>\n",
       "      <th>demand_instruments2</th>\n",
       "      <th>demand_instruments3</th>\n",
       "      <th>demand_instruments4</th>\n",
       "      <th>demand_instruments5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>-0.210973</td>\n",
       "      <td>-6.363361</td>\n",
       "      <td>-5.509449</td>\n",
       "      <td>-5.371022</td>\n",
       "      <td>-1.583637</td>\n",
       "      <td>-1.937069</td>\n",
       "      <td>-0.341810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2085</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>-1.557577</td>\n",
       "      <td>-5.198161</td>\n",
       "      <td>-4.396036</td>\n",
       "      <td>-4.265266</td>\n",
       "      <td>-2.862346</td>\n",
       "      <td>-3.498094</td>\n",
       "      <td>-2.330125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>1.016838</td>\n",
       "      <td>-0.799984</td>\n",
       "      <td>-0.040836</td>\n",
       "      <td>0.835758</td>\n",
       "      <td>-0.520122</td>\n",
       "      <td>-0.797271</td>\n",
       "      <td>0.768238</td>\n",
       "      <td>-0.973296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0348</td>\n",
       "      <td>0.109472</td>\n",
       "      <td>-1.338366</td>\n",
       "      <td>-1.538905</td>\n",
       "      <td>-1.172700</td>\n",
       "      <td>0.189448</td>\n",
       "      <td>-1.798173</td>\n",
       "      <td>1.519424</td>\n",
       "      <td>-0.264684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3661</td>\n",
       "      <td>5.387786</td>\n",
       "      <td>3.316330</td>\n",
       "      <td>0.758555</td>\n",
       "      <td>-0.700470</td>\n",
       "      <td>0.723864</td>\n",
       "      <td>-0.370940</td>\n",
       "      <td>-1.288456</td>\n",
       "      <td>0.080449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>-0.240857</td>\n",
       "      <td>-5.123659</td>\n",
       "      <td>-4.521685</td>\n",
       "      <td>-5.946617</td>\n",
       "      <td>-2.672067</td>\n",
       "      <td>-2.441713</td>\n",
       "      <td>0.872459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>2.987678</td>\n",
       "      <td>-0.172630</td>\n",
       "      <td>1.530545</td>\n",
       "      <td>1.190138</td>\n",
       "      <td>-0.999596</td>\n",
       "      <td>-1.673909</td>\n",
       "      <td>0.313007</td>\n",
       "      <td>1.037242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>3.082019</td>\n",
       "      <td>-0.061763</td>\n",
       "      <td>1.688702</td>\n",
       "      <td>-0.331869</td>\n",
       "      <td>0.250214</td>\n",
       "      <td>0.699356</td>\n",
       "      <td>0.445912</td>\n",
       "      <td>-0.737721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>1.826103</td>\n",
       "      <td>1.276445</td>\n",
       "      <td>0.121505</td>\n",
       "      <td>0.547611</td>\n",
       "      <td>-1.490001</td>\n",
       "      <td>-0.141559</td>\n",
       "      <td>-0.220383</td>\n",
       "      <td>0.643245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>0.3421</td>\n",
       "      <td>10.168115</td>\n",
       "      <td>2.326501</td>\n",
       "      <td>0.900583</td>\n",
       "      <td>1.740572</td>\n",
       "      <td>-0.720216</td>\n",
       "      <td>-0.519388</td>\n",
       "      <td>0.218609</td>\n",
       "      <td>-0.085415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     market_ids  product_ids  shares     prices         x  \\\n",
       "1             1            1  0.0099   0.000278 -0.210973   \n",
       "2             1            2  0.2085   0.000457 -1.557577   \n",
       "3             1            3  0.0090   1.016838 -0.799984   \n",
       "4             1            4  0.0348   0.109472 -1.338366   \n",
       "5             1            5  0.3661   5.387786  3.316330   \n",
       "..          ...          ...     ...        ...       ...   \n",
       "695         100            2  0.0900   0.001302 -0.240857   \n",
       "696         100            3  0.0008   2.987678 -0.172630   \n",
       "697         100            4  0.0007   3.082019 -0.061763   \n",
       "698         100            5  0.0364   1.826103  1.276445   \n",
       "699         100            6  0.3421  10.168115  2.326501   \n",
       "\n",
       "     demand_instruments0  demand_instruments1  demand_instruments2  \\\n",
       "1              -6.363361            -5.509449            -5.371022   \n",
       "2              -5.198161            -4.396036            -4.265266   \n",
       "3              -0.040836             0.835758            -0.520122   \n",
       "4              -1.538905            -1.172700             0.189448   \n",
       "5               0.758555            -0.700470             0.723864   \n",
       "..                   ...                  ...                  ...   \n",
       "695            -5.123659            -4.521685            -5.946617   \n",
       "696             1.530545             1.190138            -0.999596   \n",
       "697             1.688702            -0.331869             0.250214   \n",
       "698             0.121505             0.547611            -1.490001   \n",
       "699             0.900583             1.740572            -0.720216   \n",
       "\n",
       "     demand_instruments3  demand_instruments4  demand_instruments5  \n",
       "1              -1.583637            -1.937069            -0.341810  \n",
       "2              -2.862346            -3.498094            -2.330125  \n",
       "3              -0.797271             0.768238            -0.973296  \n",
       "4              -1.798173             1.519424            -0.264684  \n",
       "5              -0.370940            -1.288456             0.080449  \n",
       "..                   ...                  ...                  ...  \n",
       "695            -2.672067            -2.441713             0.872459  \n",
       "696            -1.673909             0.313007             1.037242  \n",
       "697             0.699356             0.445912            -0.737721  \n",
       "698            -0.141559            -0.220383             0.643245  \n",
       "699            -0.519388             0.218609            -0.085415  \n",
       "\n",
       "[600 rows x 11 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_blp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_blp.product_ids.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configured to construct nodes and weights with Monte Carlo simulation with options {seed: 0}."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_integration = pyblp.Integration('monte_carlo', size=50, specification_options={'seed': 0})\n",
    "mc_integration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the problem ...\n",
      "Initialized the problem after 00:00:00.\n",
      "\n",
      "Dimensions:\n",
      "================================\n",
      " T    N    I     K1    K2    MD \n",
      "---  ---  ----  ----  ----  ----\n",
      "100  600  5000   2     2     7  \n",
      "================================\n",
      "\n",
      "Formulations:\n",
      "==========================================\n",
      "       Column Indices:           0      1 \n",
      "-----------------------------  ------  ---\n",
      " X1: Linear Characteristics    prices   x \n",
      "X2: Nonlinear Characteristics  prices   x \n",
      "==========================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dimensions:\n",
       "================================\n",
       " T    N    I     K1    K2    MD \n",
       "---  ---  ----  ----  ----  ----\n",
       "100  600  5000   2     2     7  \n",
       "================================\n",
       "\n",
       "Formulations:\n",
       "==========================================\n",
       "       Column Indices:           0      1 \n",
       "-----------------------------  ------  ---\n",
       " X1: Linear Characteristics    prices   x \n",
       "X2: Nonlinear Characteristics  prices   x \n",
       "=========================================="
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_problem = pyblp.Problem(product_formulations, df_blp, integration=mc_integration)\n",
    "mc_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbfgsb = pyblp.Optimization(\n",
    "    'l-bfgs-b',\n",
    "    {\n",
    "        'gtol': 1e-7,\n",
    "      \n",
    "    }\n",
    ")\n",
    "\n",
    "none_array = np.full((2, 2), None)\n",
    "zero_array = np.array([[0, None], [None, 0]]) # just diagonal has to be positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving the problem ...\n",
      "\n",
      "Nonlinear Coefficient Initial Values:\n",
      "=====================================================================================\n",
      "Sigma:     prices            x        |  Sigma Squared:     prices            x      \n",
      "------  -------------  -------------  |  --------------  -------------  -------------\n",
      "prices  +1.000000E+00                 |      prices      +1.000000E+00  +1.000000E+00\n",
      "  x     +1.000000E+00  +1.000000E+00  |        x         +1.000000E+00  +2.000000E+00\n",
      "=====================================================================================\n",
      "\n",
      "Nonlinear Coefficient Lower Bounds:\n",
      "====================================\n",
      "Sigma:     prices            x      \n",
      "------  -------------  -------------\n",
      "prices  +0.000000E+00               \n",
      "  x         -INF       +0.000000E+00\n",
      "====================================\n",
      "\n",
      "Nonlinear Coefficient Upper Bounds:\n",
      "====================================\n",
      "Sigma:     prices            x      \n",
      "------  -------------  -------------\n",
      "prices      +INF                    \n",
      "  x         +INF           +INF     \n",
      "====================================\n",
      "\n",
      "Starting optimization ...\n",
      "\n",
      "GMM   Computation  Optimization   Objective   Fixed Point  Contraction  Clipped    Objective      Objective      Projected                                               \n",
      "Step     Time       Iterations   Evaluations  Iterations   Evaluations  Shares       Value       Improvement   Gradient Norm                     Theta                   \n",
      "----  -----------  ------------  -----------  -----------  -----------  -------  -------------  -------------  -------------  -------------------------------------------\n",
      " 1     00:00:00         0             1          1388         4254         0     +7.065720E+02                 +1.079111E+02  +1.000000E+00, +1.000000E+00, +1.000000E+00\n",
      " 1     00:00:00         0             2          1313         4031         0     +6.573121E+02  +4.925994E+01  +1.243412E+02  +1.068809E+00, +2.444724E-03, +9.878046E-01\n",
      " 1     00:00:00         1             3          1064         3274         0     +5.798886E+02  +7.742350E+01  +1.932462E+01  +1.080348E+00, -2.283500E-01, +0.000000E+00\n",
      " 1     00:00:00         2             4          1057         3249         0     +5.801322E+02                 +2.069340E+01  +1.060314E+00, +1.107367E-03, +3.500621E-02\n",
      " 1     00:00:00         2             5          1037         3204         0     +5.788125E+02  +1.076067E+00  +2.616713E+00  +1.071007E+00, -1.213590E-01, +1.632264E-02\n",
      " 1     00:00:00         3             6          1035         3191         0     +5.787776E+02  +3.491323E-02  +2.362223E+00  +1.056890E+00, -1.222813E-01, +2.326095E-02\n",
      " 1     00:00:00         4             7          1001         3087         0     +5.786425E+02  +1.350715E-01  +2.530157E+00  +9.782807E-01, -1.209476E-01, +2.691629E-02\n",
      " 1     00:00:00         5             8           980         3012         0     +5.785688E+02  +7.371260E-02  +7.018703E-01  +8.862638E-01, -1.170627E-01, +1.728507E-02\n",
      " 1     00:00:00         6             9           971         2986         0     +5.785678E+02  +1.024441E-03  +6.085094E-02  +8.833377E-01, -1.162345E-01, +1.474925E-02\n",
      " 1     00:00:00         7            10           972         2987         0     +5.785678E+02  +8.692566E-06  +9.129452E-04  +8.837543E-01, -1.162816E-01, +1.452877E-02\n",
      " 1     00:00:00         8            11           967         2969         0     +5.785678E+02  +1.644560E-08  +3.262398E-05  +8.837976E-01, -1.162868E-01, +1.452621E-02\n",
      "\n",
      "Optimization completed after 00:00:01.\n",
      "Computing the Hessian and and updating the weighting matrix ...\n",
      "Computed results after 00:00:01.\n",
      "\n",
      "Problem Results Summary:\n",
      "===============================================================================================\n",
      "GMM     Objective      Projected    Reduced Hessian  Reduced Hessian  Clipped  Weighting Matrix\n",
      "Step      Value      Gradient Norm  Min Eigenvalue   Max Eigenvalue   Shares   Condition Number\n",
      "----  -------------  -------------  ---------------  ---------------  -------  ----------------\n",
      " 1    +5.785678E+02  +3.262398E-05   +1.396034E+01    +2.600720E+02      0      +3.376106E+01  \n",
      "===============================================================================================\n",
      "\n",
      "Starting optimization ...\n",
      "\n",
      "GMM   Computation  Optimization   Objective   Fixed Point  Contraction  Clipped    Objective      Objective      Projected                                               \n",
      "Step     Time       Iterations   Evaluations  Iterations   Evaluations  Shares       Value       Improvement   Gradient Norm                     Theta                   \n",
      "----  -----------  ------------  -----------  -----------  -----------  -------  -------------  -------------  -------------  -------------------------------------------\n",
      " 2     00:00:00         0             1            0           100         0     +1.625741E+02                 +1.571299E+00  +8.837976E-01, -1.162868E-01, +1.452621E-02\n",
      " 2     00:00:00         0             2           638         1993         0     +1.657908E+02                 +2.270833E+01  +0.000000E+00, +2.861254E-01, +9.276000E-02\n",
      " 2     00:00:00         0             3           835         2590         0     +1.624529E+02  +1.211419E-01  +1.829298E+00  +7.785233E-01, -6.835315E-02, +2.384510E-02\n",
      " 2     00:00:00         1             4           808         2491         0     +1.622231E+02  +2.298253E-01  +2.297604E+00  +5.719147E-01, -5.077764E-02, +1.260207E-02\n",
      " 2     00:00:00         2             5           608         1908         0     +1.639572E+02                 +1.576694E+01  +0.000000E+00, -1.354523E-01, +2.050052E-01\n",
      " 2     00:00:00         2             6           754         2338         0     +1.621733E+02  +4.977920E-02  +4.517314E+00  +4.224505E-01, -7.290653E-02, +6.288472E-02\n",
      " 2     00:00:00         3             7           489         1571         0     +1.616509E+02  +5.223821E-01  +5.710988E+00  +0.000000E+00, -6.248610E-02, +9.597887E-03\n",
      " 2     00:00:00         3             8           705         2185         0     +1.620635E+02                 +3.841939E+00  +3.399246E-01, -7.087090E-02, +5.247512E-02\n",
      " 2     00:00:00         3             9           626         1967         0     +1.617912E+02                 +2.376675E+00  +1.699623E-01, -6.667850E-02, +3.103650E-02\n",
      " 2     00:00:00         3            10           519         1654         0     +1.615480E+02  +1.029045E-01  +2.116909E+00  +5.124615E-02, -6.375017E-02, +1.606195E-02\n",
      " 2     00:00:00         4            11           411         1270         0     +1.615498E+02                 +1.828174E+00  +0.000000E+00, +4.141813E-03, +0.000000E+00\n",
      " 2     00:00:00         4            12           468         1488         0     +1.614971E+02  +5.096778E-02  +3.806351E-01  +2.554322E-02, -2.969839E-02, +8.005946E-03\n",
      " 2     00:00:00         5            13           629         1969         0     +1.619231E+02                 +5.490324E+00  +1.499557E-01, +1.193861E-02, +1.512280E-03\n",
      " 2     00:00:00         5            14           476         1511         0     +1.614970E+02  +2.124949E-05  +3.748732E-01  +2.658013E-02, -2.935137E-02, +7.951825E-03\n",
      " 2     00:00:00         6            15           474         1499         0     +1.614963E+02  +7.576900E-04  +6.238025E-03  +2.633474E-02, -2.994948E-02, +4.136669E-03\n",
      " 2     00:00:00         7            16           475         1501         0     +1.614963E+02  +5.201594E-07  +2.697766E-04  +2.639465E-02, -3.004481E-02, +4.071593E-03\n",
      " 2     00:00:00         8            17           474         1507         0     +1.614963E+02  +5.491074E-10  +4.551126E-06  +2.639265E-02, -3.004095E-02, +4.071066E-03\n",
      "\n",
      "Optimization completed after 00:00:01.\n",
      "Computing the Hessian and estimating standard errors ...\n",
      "Computed results after 00:00:00.\n",
      "\n",
      "Problem Results Summary:\n",
      "==================================================================================================================\n",
      "GMM     Objective      Projected    Reduced Hessian  Reduced Hessian  Clipped  Weighting Matrix  Covariance Matrix\n",
      "Step      Value      Gradient Norm  Min Eigenvalue   Max Eigenvalue   Shares   Condition Number  Condition Number \n",
      "----  -------------  -------------  ---------------  ---------------  -------  ----------------  -----------------\n",
      " 2    +1.614963E+02  +4.551126E-06   +5.220717E+01    +1.588824E+02      0      +1.724003E+01      +7.667095E+06  \n",
      "==================================================================================================================\n",
      "\n",
      "Cumulative Statistics:\n",
      "===========================================================================\n",
      "Computation  Optimizer  Optimization   Objective   Fixed Point  Contraction\n",
      "   Time      Converged   Iterations   Evaluations  Iterations   Evaluations\n",
      "-----------  ---------  ------------  -----------  -----------  -----------\n",
      " 00:00:03       Yes          18           30          22615        70262   \n",
      "===========================================================================\n",
      "\n",
      "Nonlinear Coefficient Estimates (Robust SEs in Parentheses):\n",
      "=============================================================================================\n",
      "Sigma:      prices              x         |  Sigma Squared:      prices              x       \n",
      "------  ---------------  ---------------  |  --------------  ---------------  ---------------\n",
      "prices   +2.639265E-02                    |      prices       +6.965722E-04    -7.928603E-04 \n",
      "        (+5.355224E+00)                   |                  (+2.826771E-01)  (+4.562213E-01)\n",
      "                                          |                                                  \n",
      "  x      -3.004095E-02    +4.071066E-03   |        x          -7.928603E-04    +9.190321E-04 \n",
      "        (+1.254991E+01)  (+9.687149E+01)  |                  (+4.562213E-01)  (+1.451628E+00)\n",
      "=============================================================================================\n",
      "\n",
      "Beta Estimates (Robust SEs in Parentheses):\n",
      "================================\n",
      "    prices              x       \n",
      "---------------  ---------------\n",
      " +2.853686E-01    -6.960939E-01 \n",
      "(+6.477120E-01)  (+2.227512E+00)\n",
      "================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Problem Results Summary:\n",
       "==================================================================================================================\n",
       "GMM     Objective      Projected    Reduced Hessian  Reduced Hessian  Clipped  Weighting Matrix  Covariance Matrix\n",
       "Step      Value      Gradient Norm  Min Eigenvalue   Max Eigenvalue   Shares   Condition Number  Condition Number \n",
       "----  -------------  -------------  ---------------  ---------------  -------  ----------------  -----------------\n",
       " 2    +1.614963E+02  +4.551126E-06   +5.220717E+01    +1.588824E+02      0      +1.724003E+01      +7.667095E+06  \n",
       "==================================================================================================================\n",
       "\n",
       "Cumulative Statistics:\n",
       "===========================================================================\n",
       "Computation  Optimizer  Optimization   Objective   Fixed Point  Contraction\n",
       "   Time      Converged   Iterations   Evaluations  Iterations   Evaluations\n",
       "-----------  ---------  ------------  -----------  -----------  -----------\n",
       " 00:00:03       Yes          18           30          22615        70262   \n",
       "===========================================================================\n",
       "\n",
       "Nonlinear Coefficient Estimates (Robust SEs in Parentheses):\n",
       "=============================================================================================\n",
       "Sigma:      prices              x         |  Sigma Squared:      prices              x       \n",
       "------  ---------------  ---------------  |  --------------  ---------------  ---------------\n",
       "prices   +2.639265E-02                    |      prices       +6.965722E-04    -7.928603E-04 \n",
       "        (+5.355224E+00)                   |                  (+2.826771E-01)  (+4.562213E-01)\n",
       "                                          |                                                  \n",
       "  x      -3.004095E-02    +4.071066E-03   |        x          -7.928603E-04    +9.190321E-04 \n",
       "        (+1.254991E+01)  (+9.687149E+01)  |                  (+4.562213E-01)  (+1.451628E+00)\n",
       "=============================================================================================\n",
       "\n",
       "Beta Estimates (Robust SEs in Parentheses):\n",
       "================================\n",
       "    prices              x       \n",
       "---------------  ---------------\n",
       " +2.853686E-01    -6.960939E-01 \n",
       "(+6.477120E-01)  (+2.227512E+00)\n",
       "================================"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to restrict parameters to be lower triangular. I think. Unclear. There's some documentation here talking about Cholesky decompositions.\n",
    "# Does seem like they ahve the taste shocks baked in here to some degree 'It is common to assume that 𝑓(𝛽𝑖∣𝜃) follows a multivariate normal distribution, and to break it up into three parts: \n",
    "\n",
    "# Might need to do something for beta too. \n",
    "results = mc_problem.solve(sigma= np.ones((2,2)), optimization=lbfgsb,\n",
    "                           sigma_bounds = (zero_array,none_array))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function numpy.ones(shape, dtype=None, order='C', *, device=None, like=None)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
